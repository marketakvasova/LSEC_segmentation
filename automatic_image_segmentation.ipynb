{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marketakvasova/LSEC_segmentation/blob/main/automatic_image_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXBX4DqRE9h2"
      },
      "source": [
        "# **Automatic segmentation of electron microscope images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0RgOiEHFZyI"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N5QvbqMfiA4o",
        "outputId": "19a27305-6eda-466f-e28a-e5a2f2c8b0be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.41.0-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.42 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.41.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.4\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.1 torchmetrics-1.3.1\n",
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.16.0+cu121)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation-models-pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.0+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=62701d9be6b8088ccb4220a5122ef43c8a7d553931fe0d55167cc4f424886cdd\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=b71ef486d905ff24d2b0259b96fd6359d36b8f00cdedcf643a0b1a2bb2540054\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n",
            "Mounted at /content/gdrive\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!pip install wandb\n",
        "!pip install torchmetrics\n",
        "!pip install segmentation-models-pytorch\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from torchmetrics.classification import Dice, BinaryJaccardIndex\n",
        "import os\n",
        "from google.colab import drive\n",
        "import torch.cuda\n",
        "# from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "import shutil\n",
        "import cv2 as cv\n",
        "from numpy.lib.stride_tricks import as_strided\n",
        "import pywt\n",
        "from scipy.stats import norm\n",
        "from google.colab.patches import cv2_imshow\n",
        "import gc\n",
        "import wandb\n",
        "from numba import njit\n",
        "from scipy.signal import convolve2d\n",
        "\n",
        "# gc.collect()\n",
        "drive.mount('/content/gdrive')\n",
        "model_folder = \"./gdrive/MyDrive/ROI_patches/my_model\"\n",
        "os.makedirs(model_folder, exist_ok=True)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # TODO: do not even try this, if the gpu is not connected\n",
        "print(DEVICE)\n",
        "biomodel_folder = os.path.join(model_folder, \"bioimageio_model\")\n",
        "biomodel_path = os.path.join(biomodel_folder, \"weights.pt\")\n",
        "os.makedirs(biomodel_folder, exist_ok=True)\n",
        "LOAD_TRAINED_MODEL = False\n",
        "model_path = os.path.join(model_folder,\"my_checkpoint.pth.tar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om_n1-_pGegM"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M0WZPlvMjs0"
      },
      "source": [
        "## Data utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G5gyUZlsiNvB"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transofrm=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transofrm\n",
        "        self.images = sorted(os.listdir(self.image_dir)) # listdir returns arbitrary order\n",
        "        self.masks = sorted(os.listdir(self.mask_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.image_dir, self.images[index])\n",
        "        mask_path = os.path.join(self.mask_dir, self.masks[index]) # mask and image need to be called the same\n",
        "        image = cv.imread(img_path, cv.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "        mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "        # mask[mask == 255.0] = 1\n",
        "        mask /= 255\n",
        "        return image, mask\n",
        "\n",
        "class TransformDataset(Dataset):\n",
        "    def __init__(self, dataset, transform):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.dataset[index]\n",
        "        augmentations = self.transform(image=image, mask=mask)\n",
        "        image = augmentations[\"image\"]\n",
        "        mask = augmentations[\"mask\"]\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "def get_loaders(img_dir, mask_dir, split, batch_size, num_workers=4, pin_memory=True): # TODO: check these parameters\n",
        "    data = MyDataset(\n",
        "        image_dir=img_dir,\n",
        "        mask_dir=mask_dir,\n",
        "        transofrm=None\n",
        "    )\n",
        "\n",
        "    train_transform, val_transform = get_transforms()\n",
        "\n",
        "    train_indices, test_indices = train_test_split(\n",
        "        range(len(data)),\n",
        "        test_size=split,\n",
        "        random_state=42\n",
        "    )\n",
        "    train_data = TransformDataset(Subset(data, train_indices), train_transform)\n",
        "    val_data = TransformDataset(Subset(data, test_indices), val_transform)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_data,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, train_indices\n",
        "\n",
        "def get_transforms():\n",
        "    train_transform = A.Compose( # TODO: background(preprocessing?), intensity\n",
        "        [\n",
        "            A.Rotate(limit=35, p=1.0),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            # A.Affine(shear=(0.5,1)),\n",
        "            # A.Affine(scale=(-10, 10)),\n",
        "            A.Normalize(\n",
        "                mean = 0.0,\n",
        "                std = 1.0,\n",
        "                max_pixel_value=255.0, # normalization to [0, 1]\n",
        "            ),\n",
        "            ToTensorV2()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    val_transform = A.Compose(\n",
        "        [\n",
        "            A.Normalize(\n",
        "                mean = 0.0,\n",
        "                std = 1.0,\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2()\n",
        "        ]\n",
        "    )\n",
        "    return train_transform, val_transform\n",
        "\n",
        "# test_transform = A.Compose(\n",
        "#     [\n",
        "#     A.Normalize(\n",
        "#       mean = 0.0,\n",
        "#       std = 1.0,\n",
        "#       max_pixel_value=255.0,\n",
        "#     ),\n",
        "#         ToTensorV2()\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # Add more transformations if needed\n",
        "])\n",
        "\n",
        "\n",
        "def merge_images(image, mask):\n",
        "    merge = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
        "    merge[:, :, 0] = image # B channel (0, 1, 2) = (B, G, R)\n",
        "    merge[:, :, 2] = image # R channel\n",
        "    merge[:, :, 1] = mask # G channel\n",
        "    merge[:, :, 2][mask == 255.0] = 255 # R channel\n",
        "    merge = merge.astype('uint8')\n",
        "    return merge\n",
        "\n",
        "\n",
        "def merge_original_mask(image_path, mask_path, output_folder):\n",
        "    image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "    mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
        "    merge = merge_images(image, mask)\n",
        "    filename_ext = os.path.basename(image_path)\n",
        "    filename, ext = os.path.splitext(filename_ext)\n",
        "    cv.imwrite(os.path.join(output_folder, filename+\"_original_mask_merge\"+\".png\"), merge)\n",
        "\n",
        "\n",
        "def merge_masks(mask1_path, mask2_path, output_folder):\n",
        "    mask1 = cv.imread(mask1_path, cv.IMREAD_GRAYSCALE)\n",
        "    mask2 = cv.imread(mask2_path, cv.IMREAD_GRAYSCALE)\n",
        "    # merge = merge_images(image, mask)\n",
        "    merge = np.zeros((mask1.shape[0], mask1.shape[1], 3))\n",
        "\n",
        "    merge[:, :, 1][mask1 == 255.0] = 255\n",
        "    merge[:, :, 2][mask2 == 255.0] = 255\n",
        "\n",
        "    filename_ext = os.path.basename(mask1_path)\n",
        "    filename, ext = os.path.splitext(filename_ext)\n",
        "    cv.imwrite(os.path.join(output_folder, filename+\"_mask_compare\"+\".png\"), merge)\n",
        "\n",
        "\n",
        "def create_weighting_patches(patch_size, edge_size):\n",
        "    patch = np.ones((patch_size, patch_size), dtype=float)\n",
        "\n",
        "    # Calculate the linear decrease values\n",
        "    decrease_values = np.linspace(1, 0, num=edge_size)\n",
        "    decrease_values = np.tile(decrease_values, (patch_size, 1))\n",
        "    increase_values = np.linspace(0, 1, num=edge_size)\n",
        "    increase_values = np.tile(increase_values, (patch_size, 1))\n",
        "\n",
        "    # Middle patch\n",
        "    # Apply linear decrease to all four edges\n",
        "    middle = patch.copy()\n",
        "    middle[:, 0:edge_size] *= increase_values\n",
        "    middle[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    middle[0:edge_size, :] *= increase_values.T\n",
        "    middle[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((middle*255).astype(np.uint8))\n",
        "\n",
        "    # Left\n",
        "    left = patch.copy()\n",
        "    left[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    left[0:edge_size, :] *= increase_values.T\n",
        "    left[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((left*255).astype(np.uint8))\n",
        "\n",
        "    # Right\n",
        "    right = patch.copy()\n",
        "    right[:, 0:edge_size] *= increase_values\n",
        "    right[0:edge_size, :] *= increase_values.T\n",
        "    right[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((right*255).astype(np.uint8))\n",
        "\n",
        "    # Top\n",
        "    top = patch.copy()\n",
        "    top[:, 0:edge_size] *= increase_values\n",
        "    top[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    top[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((top*255).astype(np.uint8))\n",
        "\n",
        "    # Bottom\n",
        "    bottom = patch.copy()\n",
        "    bottom[:, 0:edge_size] *= increase_values\n",
        "    bottom[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    bottom[0:edge_size, :] *= increase_values.T\n",
        "    # cv2_imshow((bottom*255).astype(np.uint8))\n",
        "\n",
        "    # Left Top edge\n",
        "    top_left = patch.copy()\n",
        "    top_left[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    top_left[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((top_left*255).astype(np.uint8))\n",
        "\n",
        "    # Right top edge\n",
        "    top_right = patch.copy()\n",
        "    top_right[:, 0:edge_size] *= increase_values\n",
        "    top_right[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((top_right*255).astype(np.uint8))\n",
        "\n",
        "    # Left bottom edge\n",
        "    bottom_left = patch.copy()\n",
        "    bottom_left[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    bottom_left[0:edge_size, :] *= increase_values.T\n",
        "    # cv2_imshow((bottom_left*255).astype(np.uint8))\n",
        "\n",
        "    # Right Bottom edge\n",
        "    bottom_right = patch.copy()\n",
        "    bottom_right[:, 0:edge_size] *= increase_values\n",
        "    bottom_right[0:edge_size, :] *= increase_values.T\n",
        "    # cv2_imshow((bottom_right*255).astype(np.uint8))\n",
        "\n",
        "    return middle, top_left, top, top_right, right, bottom_right, bottom, bottom_left, left\n",
        "\n",
        "\n",
        "def inference_on_image_with_overlap(model, image_path, output_folder):\n",
        "    window_size = 512\n",
        "    oh, ow = 124, 124\n",
        "    input_image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "    image_height, image_width = input_image.shape\n",
        "    original_height, original_width = image_height, image_width\n",
        "    bottom_edge = image_height % (window_size - oh)\n",
        "    right_edge = image_width % (window_size - ow)\n",
        "    mirrored_image = np.zeros((image_height+bottom_edge, image_width+right_edge)).astype(np.uint8)\n",
        "    mirrored_image[:image_height, :image_width] = input_image\n",
        "    mirrored_image[image_height:, :image_width] = np.flipud(input_image[image_height-bottom_edge:, :])\n",
        "    mirrored_image[:, image_width:] = np.fliplr(mirrored_image[:, image_width-right_edge:image_width])\n",
        "    image_height += bottom_edge\n",
        "    image_width += right_edge\n",
        "    weights = np.zeros((image_height, image_width))\n",
        "    # tryout = np.zeros((image_height, image_width))\n",
        "    output_probs = np.zeros((image_height, image_width))\n",
        "    output_mask = np.zeros((image_height, image_width))\n",
        "    middle, top_left, top, top_right, right, bottom_right, bottom, bottom_left, left = create_weighting_patches(window_size, oh)\n",
        "\n",
        "    for x in range(0, image_height-window_size+1, window_size - oh):\n",
        "        for y in range(0, image_width-window_size+1, window_size - ow):\n",
        "            # Choose weighting window\n",
        "            if x == 0:\n",
        "                if y == 0:\n",
        "                    weighting_window = top_left\n",
        "                elif y == window_size - ow - 1:\n",
        "                    weighting_window = top_right\n",
        "                else:\n",
        "                    weighting_window = top\n",
        "            elif x == window_size - oh - 1:\n",
        "                if y == 0:\n",
        "                    weighting_window = bottom_left\n",
        "                elif y == window_size - ow - 1:\n",
        "                    weighting_window = bottom_right\n",
        "                else:\n",
        "                    weighting_window = bottom\n",
        "            elif y == 0:\n",
        "                weighting_window = left\n",
        "            elif y == window_size - ow - 1:\n",
        "                weighting_window = right\n",
        "            else:\n",
        "                weighting_window = middle\n",
        "            square_section = mirrored_image[x:x + window_size, y:y + window_size]\n",
        "            weights[x:x + window_size, y:y + window_size] += 1\n",
        "            # tryout[x:x + window_size, y:y + window_size] += np.ones((window_size, window_size))*weighting_window\n",
        "            square_section = preprocess_image(square_section)\n",
        "            square_tensor = test_transform(square_section).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
        "\n",
        "            # Forward pass through the model\n",
        "            with torch.no_grad():\n",
        "                output = torch.sigmoid(model(square_tensor)).float()\n",
        "\n",
        "            # Scale the probablity to 0-255\n",
        "            output = output*255\n",
        "            output = output.to(torch.uint8)\n",
        "            output_pil = output.squeeze(0).cpu().numpy()\n",
        "            output_probs[x:x+window_size, y:y+window_size] += output_pil.squeeze()*weighting_window\n",
        "    # Crop\n",
        "    output_probs = output_probs[:original_height, :original_width]\n",
        "    weights = weights[:original_height, :original_width]\n",
        "    # tryout = tryout[:original_height, :original_width]*255\n",
        "\n",
        "    # Apply weights\n",
        "    # output_probs /= weights\n",
        "\n",
        "    # Create image from mask\n",
        "    output_mask = np.where(output_probs > 127, 255, 0)\n",
        "    output_mask = output_mask.astype(np.uint8)\n",
        "    filename_ext = os.path.basename(image_path)\n",
        "    filename, ext = os.path.splitext(filename_ext)\n",
        "\n",
        "    # Merge image with created mask\n",
        "    out_mask_path = os.path.join(output_folder, filename+\"_mask\"+\".png\")\n",
        "    merge = merge_images(input_image, output_mask)\n",
        "    cv.imwrite(os.path.join(output_folder, filename+\"_merge\"+\".png\"), merge)\n",
        "\n",
        "    cv.imwrite(os.path.join(output_folder, filename+\"_probs\"+\".png\"), output_probs)\n",
        "    cv.imwrite(out_mask_path, output_mask)\n",
        "    # cv.imwrite(os.path.join(output_folder, filename+\"_tryout\"+\".png\"), tryout)\n",
        "    return out_mask_path\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "    image = nlm_filt(image)\n",
        "    # image = wavelet_denoise(image, threshold=1.5)\n",
        "    image = apply_clahe(image)\n",
        "    # image = cv.medianBlur(image, 7)\n",
        "    return image\n",
        "\n",
        "\n",
        "def apply_clahe(image):\n",
        "    clahe = cv.createCLAHE(clipLimit=0.8, tileGridSize=(8, 8))\n",
        "    clahe_image = clahe.apply(image)\n",
        "    return clahe_image\n",
        "\n",
        "\n",
        "def create_image_patches(image_folder, mask_folder, output_folder, patch_size):\n",
        "    image_patches_path = os.path.join(output_folder,'image_patches')\n",
        "    mask_patches_path = os.path.join(output_folder,'mask_patches')\n",
        "    # rejected_path = os.path.join(output_folder,'rejected')\n",
        "    # print(image_path)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    if os.path.exists(image_patches_path):\n",
        "        shutil.rmtree(image_patches_path)\n",
        "    os.mkdir(image_patches_path)\n",
        "    if os.path.exists(mask_patches_path):\n",
        "        shutil.rmtree(mask_patches_path)\n",
        "    os.mkdir(mask_patches_path)\n",
        "    # if os.path.exists(rejected_path):\n",
        "    #     shutil.rmtree(rejected_path)\n",
        "    # os.mkdir(rejected_path)\n",
        "\n",
        "    patch_area = patch_size**2\n",
        "    fenestration_area_thresh = 0.05\n",
        "    image_filenames = sorted(os.listdir(image_folder))\n",
        "    mask_filenames = sorted(os.listdir(mask_folder))\n",
        "\n",
        "    for image_name, mask_name in zip(image_filenames, mask_filenames):\n",
        "        if image_name.endswith(\".tif\"):\n",
        "            input_path = os.path.join(image_folder, image_name)\n",
        "            mask_path = os.path.join(mask_folder, mask_name)\n",
        "\n",
        "            img = cv.imread(input_path, cv.IMREAD_GRAYSCALE)\n",
        "            mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
        "            height, width = img.shape\n",
        "\n",
        "            shape = (height // patch_size, width // patch_size, patch_size, patch_size)\n",
        "            strides = (patch_size * width , patch_size , width, 1)\n",
        "            # strides = (patch_size * width , patch_size)\n",
        "\n",
        "            # img_strided = as_strided(img, shape=(width//patch_size, height//patch_size, patch_size, patch_size),\n",
        "            #              strides=img.strides + img.strides, writeable=False)\n",
        "            img_strided = as_strided(img, shape=shape,\n",
        "                          strides=strides, writeable=False) #TODO: check if the patches do not overlap\n",
        "            mask_strided = as_strided(mask, shape=shape,\n",
        "                          strides=strides, writeable=False)\n",
        "\n",
        "            for i in range(img_strided.shape[0]):\n",
        "                for j in range(img_strided.shape[1]):\n",
        "                    img_patch = img_strided[i, j]\n",
        "                    mask_patch = mask_strided[i, j]\n",
        "                    # Compute the percentage of white pixels\n",
        "                    fenestration_area = np.sum(mask_patch == 255)\n",
        "                    fenestration_percentage = fenestration_area/patch_area\n",
        "                    if fenestration_area > fenestration_area_thresh:\n",
        "                        patch_filename = f\"{os.path.splitext(os.path.basename(image_name))[0]}_patch_{i}_{j}.tif\"\n",
        "                        # preprocess image\n",
        "                        img_patch = preprocess_image(img_patch)\n",
        "                        cv.imwrite(os.path.join(image_patches_path, patch_filename), img_patch)\n",
        "                        cv.imwrite(os.path.join(mask_patches_path, patch_filename), mask_patch)\n",
        "                        # print(\"written patch \", patch_filename)\n",
        "                    else:\n",
        "                        print(\"not writing patch\")\n",
        "    return image_patches_path, mask_patches_path\n",
        "\n",
        "\n",
        "# Denoising\n",
        "#   References for non-local means filtering and noise variance estimation:\n",
        "#\n",
        "#   [1] Antoni Buades, Bartomeu Coll, and Jean-Michel Morel, A Non-Local\n",
        "#       Algorithm for Image Denoising, Computer Vision and Pattern\n",
        "#       Recognition 2005. CVPR 2005, Volume 2, (2005), pp. 60-65.\n",
        "#   [2] John Immerkaer, Fast Noise Variance Estimation, Computer Vision and\n",
        "#       Image Understanding, Volume 64, Issue 2, (1996), pp. 300-302\n",
        "\n",
        "def estimate_degree_of_smoothing(I): # This is how the estimation is done in Matlab (see imnlmfilt in Matlab)\n",
        "    H, W = I.shape\n",
        "    I = I.astype(np.float32)\n",
        "    kernel = np.array([[1, -2, 1], [-2, 4, -2], [1, -2, 1]])\n",
        "    conv_result = np.abs(convolve2d(I[:, :], kernel, mode='valid'))\n",
        "    res = np.sum(conv_result)\n",
        "    degree_of_smoothing = (res * np.sqrt(0.5 * np.pi) / (6 * (W - 2) * (H - 2)))\n",
        "    if degree_of_smoothing == 0:\n",
        "        degree_of_smoothing = np.finfo(np.float32).eps\n",
        "    return degree_of_smoothing\n",
        "\n",
        "\n",
        "def nlm_filt(image):\n",
        "    window_size = 5\n",
        "    search_window_size = 21\n",
        "    degree_of_smoothing = estimate_degree_of_smoothing(image)\n",
        "    image = cv2.fastNlMeansDenoising(image, None, h = degree_of_smoothing, templateWindowSize = 5, searchWindowSize = 21)\n",
        "    return image\n",
        "\n",
        "\n",
        "def anscombe_transform(data):\n",
        "    return 2.0 * np.sqrt(data + 3.0/8.0)\n",
        "\n",
        "\n",
        "def inverse_anscombe_transform(data):\n",
        "    # Reference\n",
        "    # https://github.com/broxtronix/pymultiscale/blob/master/pymultiscale/anscombe.py\n",
        "    return (1.0/4.0 * np.power(data, 2) +\n",
        "        1.0/4.0 * np.sqrt(3.0/2.0) * np.power(data, -1.0) -\n",
        "        11.0/8.0 * np.power(data, -2.0) +\n",
        "        5.0/8.0 * np.sqrt(3.0/2.0) * np.power(data, -3.0) - 1.0 / 8.0)\n",
        "\n",
        "\n",
        "def wavelet_denoising(data, threshold=1.5, wavelet='coif4', threshold_type='soft'):\n",
        "    coeffs = pywt.wavedec2(data, wavelet = wavelet, level=3)\n",
        "    coeffs[-1] = tuple(pywt.threshold(c, threshold, threshold_type) for c in coeffs[-1])\n",
        "    coeffs[-2] = tuple(pywt.threshold(c, threshold, threshold_type) for c in coeffs[-2])\n",
        "    coeffs[-3] = tuple(pywt.threshold(c, threshold, threshold_type) for c in coeffs[-3])\n",
        "    return pywt.waverec2(coeffs, wavelet)\n",
        "\n",
        "\n",
        "def wavelet_denoise(image, threshold):\n",
        "    image = anscombe_transform(image)\n",
        "    image = wavelet_denoising(image, threshold)\n",
        "    image = inverse_anscombe_transform(image)\n",
        "    # TODO: not sure this is the correct way how to do this\n",
        "    image = image/np.max(image)*255\n",
        "    return image.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLHlKdZ_MnGj"
      },
      "source": [
        "## Training utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dvOsCa6iiNrd"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, model_path):#, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    model.save(model_path)\n",
        "    # torch.save(state, filename)\n",
        "\n",
        "def save_state_dict(model, model_path):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "def load_state_dict(model, model_path):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "def validate_model(model, loader, loss_fn):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(DEVICE)\n",
        "            y = y.float().to(DEVICE).unsqueeze(1)\n",
        "            # Forward\n",
        "            preds = model(x)\n",
        "            # loss_fn = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(16))\n",
        "            loss = loss_fn(preds, y)\n",
        "            running_loss += loss.cpu()\n",
        "            preds = (preds > 0.5).float()\n",
        "\n",
        "            # num_correct += (preds == y).sum()\n",
        "            # num_pixels += torch.numel(preds)\n",
        "            dice_score += (2*(preds*y).sum()) / (preds+y).sum() + 1e-8 # this is a better predictor\n",
        "    # print(\n",
        "    #     f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f} ()\"\n",
        "    # )\n",
        "    dice_score = dice_score/len(loader)\n",
        "    val_loss = running_loss/len(loader) #TODO: not sure this is correct(dividing by batch size?)\n",
        "    # print(f\"Dice score is {dice_score}\")\n",
        "    # val_losses.append(running_loss/len(loader))\n",
        "    # dice_scores.append(dice_score.cpu())\n",
        "    model.train()\n",
        "    return val_loss, dice_score.cpu()\n",
        "\n",
        "\n",
        "\n",
        "# def save_predictions_as_imgs(\n",
        "#         loader, model, folder=\"saved_images\", device=\"cpu\"\n",
        "# ):\n",
        "#     model.eval()\n",
        "#     for idx, (x, y) in enumerate(loader):\n",
        "#         x = x.to(device=device)\n",
        "#         with torch.no_grad():\n",
        "#             preds = torch.sigmoid(model(x))\n",
        "#             preds = (preds > 0.5).float()\n",
        "#         # print(f\"preds max{preds.max()}\")\n",
        "#         # print(f\"y max {y.max()}\")\n",
        "#         # torchvision.utils.save_image(preds, os.path.join(folder, f\"pred{idx}.png\"))\n",
        "#         # torchvision.utils.save_image(y.unsqueeze(1), os.path.join(folder, f\"pred{idx}_correct.png\"))\n",
        "#             imshow(preds)\n",
        "#             imshow(y.unsqueeze(1))\n",
        "#         break # TODO: change this so it does not loop\n",
        "#     model.train()\n",
        "#     print(\"Saving prediction as images.\")\n",
        "\n",
        "def view_prediction(loader, model, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        x = x.to(device=device)\n",
        "        with torch.no_grad():\n",
        "            # output = torch.softmax(model(x), dim=1)\n",
        "            output = torch.sigmoid(model(x))\n",
        "            preds = (output > 0.5).float()\n",
        "            preds = preds.cpu().data.numpy()\n",
        "            output = output.cpu().data.numpy()\n",
        "            for i in range(preds.shape[0]):\n",
        "                f=plt.figure(figsize=(128,32))\n",
        "                # Original image\n",
        "                plt.subplot(1,5*preds.shape[0],i+1)\n",
        "                x = x.cpu()\n",
        "                plt.imshow(x[i, 0, :, :], cmap='gray') # preds is a batch\n",
        "                plt.title('Validation image')\n",
        "                # NN output(probability)\n",
        "                plt.subplot(1,5*preds.shape[0],i+2)\n",
        "                plt.imshow(output[i, 0, :, :], interpolation='nearest', cmap='magma') # preds is a batch\n",
        "                plt.title('NN output')\n",
        "                # Segmentation\n",
        "                plt.subplot(1,5*preds.shape[0],i+3)\n",
        "                plt.imshow(preds[i, 0, :, :], cmap='gray') # preds is a batch\n",
        "                plt.title('Prediction')\n",
        "                # True mask\n",
        "                plt.subplot(1,5*preds.shape[0],i+4)\n",
        "                plt.imshow(y.unsqueeze(1)[i, 0, :, :], cmap='gray')\n",
        "                plt.title('Ground truth')\n",
        "                # IoU\n",
        "                plt.subplot(1,5*preds.shape[0],i+5)\n",
        "                im1 = y.unsqueeze(1)[i, 0, :, :]\n",
        "                im2 = preds[i, 0, :, :]\n",
        "                plt.imshow(im1, alpha=0.8, cmap='Blues')\n",
        "                plt.imshow(im2, alpha=0.6,cmap='Oranges')\n",
        "                plt.title('IoU')\n",
        "\n",
        "            plt.show()\n",
        "            break # TODO: change this so it does not loop\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def getClassWeights(mask_path, train_indices):\n",
        "    mask_dir_list = sorted(os.listdir(mask_path))\n",
        "    class_count = np.zeros(2, dtype=int)\n",
        "    for i in train_indices:\n",
        "        mask = cv.imread(os.path.join(mask_path, mask_dir_list[i]), cv.IMREAD_GRAYSCALE) #np.array(Image.open(os.path.join(mask_path, mask_dir_list[i])).convert('L'), dtype=np.float32)\n",
        "        mask[mask == 255.0] = 1\n",
        "        class_count[0] += mask.shape[0]*mask.shape[1] - mask.sum()\n",
        "        class_count[1] += mask.sum()\n",
        "\n",
        "    n_samples = class_count.sum()\n",
        "    n_classes = 2\n",
        "\n",
        "    class_weights = n_samples / (n_classes * class_count)\n",
        "    return torch.from_numpy(class_weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debug"
      ],
      "metadata": {
        "id": "FUoJD88eOFO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def show_fitted_ellipses(image_path, ellipses):\n",
        "    image = cv2.imread(image_path)\n",
        "    for ellipse in ellipses:\n",
        "        cv2.ellipse(image, ellipse, (0, 0, 255), 1)\n",
        "        center, axes, angle = ellipse\n",
        "        center_x, center_y = center\n",
        "        major_axis_length, minor_axis_length = axes\n",
        "        rotation_angle = angle\n",
        "        # print(center_x, center_y)\n",
        "        cv2.circle(image, (int(center_x), int(center_y)),radius=1, color=(0, 0, 255), thickness=-1)\n",
        "\n",
        "        # print(\"Center:\", center)\n",
        "        # print(\"Major Axis Length:\", major_axis_length)\n",
        "        # print(\"Minor Axis Length:\", minor_axis_length)\n",
        "        # print(\"Rotation Angle:\", rotation_angle)\n",
        "\n",
        "    cv2_imshow(image)\n",
        "\n",
        "def fit_ellipses(filtered_contours, centers):\n",
        "    ellipses = []\n",
        "    for contour, cnt_center in zip(filtered_contours, centers):\n",
        "        if len(contour) >= 5:  # Ellipse fitting requires at least 5 points\n",
        "            ellipse = cv2.fitEllipse(contour) # TODO: maybe try a different computation, if this does not work well\n",
        "            # ellipse = cv2.minAreaRect(cnt) # the fitEllipse functions fails sometimes(when the fenestration is on the edge and only a part of it is visible)\n",
        "            dist = cv2.norm(cnt_center, ellipse[0])\n",
        "            # print(dist)\n",
        "            if dist < 20:\n",
        "                ellipses.append(ellipse)\n",
        "    return ellipses\n",
        "\n",
        "def find_fenestration_contours(image_path):\n",
        "    seg_mask = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    contours, _ = cv2.findContours(seg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # image = cv2.cvtColor(seg_mask, cv2.COLOR_GRAY2RGB)\n",
        "    # image_el = image.copy()\n",
        "    # cv2.drawContours(image, contours, -1, (0, 0, 255), 1)\n",
        "    # cv2_imshow(image)\n",
        "\n",
        "    # Remove noise and small artifacts\n",
        "    min_contour_area = 10\n",
        "    filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\n",
        "    return filtered_contours\n",
        "\n",
        "def find_contour_centers(contours):\n",
        "    contour_centers = []\n",
        "    for cnt in contours:\n",
        "        M = cv2.moments(cnt)\n",
        "        center_x = int(M['m10'] / M['m00'])\n",
        "        center_y = int(M['m01'] / M['m00'])\n",
        "        contour_centers.append((center_x, center_y))\n",
        "    return contour_centers\n",
        "\n",
        "def equivalent_circle_diameter(major_axis_length, minor_axis_length):\n",
        "    return math.sqrt(4 * major_axis_length * minor_axis_length)\n",
        "\n",
        "def show_statistics(fenestration_areas, fenestration_areas_from_ellipses, roundness_of_ellipses, equivalent_diameters):\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    # Plot histogram of fenestration areas\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.hist(fenestration_areas, bins=20, color='red', edgecolor='black')\n",
        "    plt.title('Histogram of Fenestration Areas')\n",
        "    plt.xlabel('Area ($\\mathrm{nm}^2$)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot histogram of areas of fitted elipses\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.hist(fenestration_areas_from_ellipses, bins=20, color='red', edgecolor='black')\n",
        "    plt.title('Histogram of Fenestration Areas')\n",
        "    plt.xlabel('Area ($\\mathrm{nm}^2$)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot histogram of roundness\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.hist(roundness_of_ellipses, bins=10, color='blue', edgecolor='black')\n",
        "    plt.title('Histogram of Roundness')\n",
        "    plt.xlabel('Roundness (-)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "    print(np.array(roundness_of_ellipses).max())\n",
        "\n",
        "    # Plot histogram of equivalent circle diameters\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.hist(equivalent_diameters, bins=20, color='green', edgecolor='black')\n",
        "    plt.title('Histogram of Equivalent Circle Diameters')\n",
        "    plt.xlabel('Diameter (nm)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "\n",
        "\n",
        "\n",
        "# Mask statistics debug\n",
        "# One pixel corresponds to 10.62 nm\n",
        "image_path = \"./gdrive/MyDrive/ROIs_manually_corrected/augment_mask/_0_379.tif\"\n",
        "image_path = \"./gdrive/MyDrive/lsec_test/old11_CA150_NE_01_original_mask.tif\" # Image from semiautomatic labeling\n",
        "\n",
        "\n",
        "pixel_size_nm = 10.62\n",
        "contours = find_fenestration_contours(image_path)\n",
        "fenestration_areas = [cv2.contourArea(cnt) * (pixel_size_nm**2) for cnt in contours]\n",
        "contour_centers = find_contour_centers(contours)\n",
        "ellipses = fit_ellipses(contours, contour_centers)\n",
        "\n",
        "# Show image of fitted ellipses\n",
        "# show_fitted_ellipses(image_path, ellipses)\n",
        "\n",
        "roundness_of_ellipses = []\n",
        "equivalent_diameters = []\n",
        "fenestration_areas_from_ellipses = []\n",
        "\n",
        "for ellipse in ellipses:\n",
        "    center, axes, angle = ellipse\n",
        "    # center_x, center_y = center\n",
        "    major_axis_length, minor_axis_length = axes\n",
        "    roundness = minor_axis_length/major_axis_length\n",
        "    roundness_of_ellipses.append(roundness)\n",
        "    # rotation_angle = angle\n",
        "    diameter = pixel_size_nm * equivalent_circle_diameter(major_axis_length, minor_axis_length)\n",
        "    equivalent_diameters.append(diameter)\n",
        "    fenestration_areas_from_ellipses.append((diameter**2)/4*math.pi)\n",
        "\n",
        "show_statistics(fenestration_areas, fenestration_areas_from_ellipses, roundness_of_ellipses, equivalent_diameters)\n",
        "\n",
        "\n",
        "# Display the number of circles and their fitted ellipses\n",
        "print(\"Number of fenestrations:\", len(contours))\n",
        "print(\"Number of fitted ellipses:\", len(ellipses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "BtPrBpQBcsmn",
        "outputId": "1b430441-738a-410a-c7a0-cfdc17d91d35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "zero-size array to reduction operation maximum which has no identity",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-de5faacbb62d>\u001b[0m in \u001b[0;36m<cell line: 129>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mfenestration_areas_from_ellipses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiameter\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mshow_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfenestration_areas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfenestration_areas_from_ellipses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroundness_of_ellipses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequivalent_diameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-de5faacbb62d>\u001b[0m in \u001b[0;36mshow_statistics\u001b[0;34m(fenestration_areas, fenestration_areas_from_ellipses, roundness_of_ellipses, equivalent_diameters)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroundness_of_ellipses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# Plot histogram of equivalent circle diameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     39\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     40\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
            "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Wavelet filtering debug\n",
        "\n",
        "image_folder = \"./gdrive/MyDrive/ROIs_manually_corrected/train_images\"\n",
        "images = os.listdir(image_folder)\n",
        "image_name = images[0]\n",
        "image = cv.imread(os.path.join(image_folder, image_name), cv.IMREAD_GRAYSCALE)\n",
        "# cv2_imshow(image)\n",
        "\n",
        "denoised_image = wavelet_denoise(image)\n",
        "# cv2_imshow(denoised_image)\n",
        "\n"
      ],
      "metadata": {
        "id": "P9hdx_pYOOjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w8Va0EXGIlq"
      },
      "source": [
        "# U-Net definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mSqH1xk-iNpJ"
      },
      "outputs": [],
      "source": [
        "# import torchvision.transforms.functional as TF\n",
        "\n",
        "\n",
        "def double_conv(in_ch, out_ch, activation):\n",
        "    if activation == 'ReLU':\n",
        "        conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=out_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    elif activation == 'GeLU':\n",
        "        conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.GeLU(approximate='none'),\n",
        "            nn.Conv2d(in_channels=out_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.GeLU(approximate='none')\n",
        "        )\n",
        "    return conv\n",
        "\n",
        "\n",
        "def padder(left_tensor, right_tensor, device: str):\n",
        "  # left_tensor is the tensor on the encoder side of UNET\n",
        "  # right_tensor is the tensor on the decoder side  of the UNET\n",
        "\n",
        "    if left_tensor.shape != right_tensor.shape:\n",
        "        padded = torch.zeros(left_tensor.shape)\n",
        "        padded[:, :, :right_tensor.shape[2], :right_tensor.shape[3]] = right_tensor\n",
        "        return padded.to(device)\n",
        "\n",
        "    return right_tensor.to(device)\n",
        "\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, device, dropout_probability, activations, out_activation):\n",
        "        super(UNET, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.device = device\n",
        "        self.dropout = nn.Dropout(p=dropout_probability)\n",
        "        self.activations = activations\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "        self.down_conv_1 = double_conv(in_ch=self.in_channels,out_ch=64, activation=activations)\n",
        "        self.down_conv_2 = double_conv(in_ch=64,out_ch=128, activation=activations)\n",
        "        self.down_conv_3 = double_conv(in_ch=128,out_ch=256, activation=activations)\n",
        "        self.down_conv_4 = double_conv(in_ch=256,out_ch=512, activation=activations)\n",
        "        self.down_conv_5 = double_conv(in_ch=512,out_ch=1024, activation=activations)\n",
        "        #print(self.down_conv_1)\n",
        "\n",
        "        self.up_conv_trans_1 = nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=2,stride=2)\n",
        "        self.up_conv_trans_2 = nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=2,stride=2)\n",
        "        self.up_conv_trans_3 = nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=2,stride=2)\n",
        "        self.up_conv_trans_4 = nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=2,stride=2)\n",
        "\n",
        "        self.up_conv_1 = double_conv(in_ch=1024,out_ch=512, activation=activations)\n",
        "        self.up_conv_2 = double_conv(in_ch=512,out_ch=256, activation=activations)\n",
        "        self.up_conv_3 = double_conv(in_ch=256,out_ch=128, activation=activations)\n",
        "        self.up_conv_4 = double_conv(in_ch=128,out_ch=64, activation=activations)\n",
        "\n",
        "        self.conv_1x1 = nn.Conv2d(in_channels=64,out_channels=self.out_channels,kernel_size=1,stride=1)\n",
        "        self.out_activation = out_activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = x.to(self.device)\n",
        "        x1 = self.down_conv_1(x)\n",
        "        p1 = self.max_pool(x1)\n",
        "        x2 = self.down_conv_2(p1)\n",
        "        p2 = self.max_pool(x2)\n",
        "        p2 = self.dropout(p2)\n",
        "        x3 = self.down_conv_3(p2)\n",
        "        p3 = self.max_pool(x3)\n",
        "        p3 = self.dropout(p3)\n",
        "        x4 = self.down_conv_4(p3)\n",
        "        p4 = self.max_pool(x4)\n",
        "        p4 = self.dropout(p4)\n",
        "        x5 = self.down_conv_5(p4)\n",
        "\n",
        "        # decoding\n",
        "        d1 = self.up_conv_trans_1(x5)  # up transpose convolution (\"up sampling\" as called in UNET paper)\n",
        "        pad1 = padder(x4,d1, self.device) # padding d1 to match x4 shape\n",
        "        cat1 = torch.cat([x4,pad1],dim=1) # concatenating padded d1 and x4 on channel dimension(dim 1) [batch(dim 0),channel(dim 1),height(dim 2),width(dim 3)]\n",
        "        cat1 = self.dropout(cat1)\n",
        "        uc1 = self.up_conv_1(cat1) # 1st up double convolution\n",
        "\n",
        "        d2 = self.up_conv_trans_2(uc1)\n",
        "        pad2 = padder(x3,d2, self.device)\n",
        "        cat2 = torch.cat([x3,pad2],dim=1)\n",
        "        cat2 = self.dropout(cat2)\n",
        "        uc2 = self.up_conv_2(cat2)\n",
        "\n",
        "        d3 = self.up_conv_trans_3(uc2)\n",
        "        pad3 = padder(x2,d3, self.device)\n",
        "        cat3 = torch.cat([x2,pad3],dim=1)\n",
        "        uc3 = self.up_conv_3(cat3)\n",
        "\n",
        "        d4 = self.up_conv_trans_4(uc3)\n",
        "        pad4 = padder(x1,d4, self.device)\n",
        "        cat4 = torch.cat([x1,pad4],dim=1)\n",
        "        uc4 = self.up_conv_4(cat4)\n",
        "\n",
        "        conv_1x1 = self.conv_1x1(uc4)\n",
        "        if self.out_activation == 'sigmoid':\n",
        "            conv_1x1 = torch.sigmoid(conv_1x1)\n",
        "        return conv_1x1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIOOv16zNmOp"
      },
      "source": [
        "# Training function definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4GQhPsENrxX"
      },
      "outputs": [],
      "source": [
        "# def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
        "#     loop = tqdm(loader)\n",
        "#     running_loss = 0\n",
        "#     # model.train()\n",
        "#     for batch_idx, (data, targets) in enumerate(loop):\n",
        "#         data = data.to(device=DEVICE)\n",
        "#         targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
        "\n",
        "#     # forward\n",
        "#         with torch.cuda.amp.autocast():\n",
        "#             predictions = model(data) # TODO: shoud this be wrapped in sigmoid???\n",
        "#             loss = loss_fn(torch.sigmoid(predictions), targets)\n",
        "\n",
        "#         # backward\n",
        "#         optimizer.zero_grad() # Zero the gradients\n",
        "\n",
        "#         # loss.backward()\n",
        "#         # optimizer.step()\n",
        "#         scaler.scale(loss).backward()\n",
        "#         scaler.step(optimizer)\n",
        "#         scaler.update()\n",
        "#         running_loss += loss.item()\n",
        "\n",
        "#         # update tqdm loop\n",
        "#         loop.set_postfix(loss = loss.item())\n",
        "#         # print(batch_idx)\n",
        "#     number_of_batches = batch_idx+1\n",
        "#     # train_losses.append(running_loss/number_of_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Patch creation"
      ],
      "metadata": {
        "id": "4YW6LWTd45uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CREATE_NEW_PATCHES = False\n",
        "SAVE_PATCHES_TO_DISK = False\n",
        "CREATE_NEW_PATCHES = True\n",
        "SAVE_PATCHES_TO_DISK = True\n",
        "# Example usage:\n",
        "\n",
        "image_folder = \"./gdrive/MyDrive/ROIs_manually_corrected/train_images\"\n",
        "mask_folder = \"./gdrive/MyDrive/ROIs_manually_corrected/train_masks\"\n",
        "\n",
        "if CREATE_NEW_PATCHES:\n",
        "    patch_size = 512  # Define your patch size here\n",
        "    if SAVE_PATCHES_TO_DISK:\n",
        "        output_folder = \"./gdrive/MyDrive/ROIs_manually_corrected/patches\"\n",
        "    else:\n",
        "        output_folder = os.getcwd()\n",
        "    image_patches_path, mask_patches_path = create_image_patches(image_folder, mask_folder, output_folder, patch_size)\n",
        "else: # The patches will be read from disk\n",
        "    output_folder = \"./gdrive/MyDrive/ROIs_manually_corrected/patches\"\n",
        "    image_patches_path = os.path.join(output_folder, 'image_patches')\n",
        "    mask_patches_path = os.path.join(output_folder, 'mask_patches')\n"
      ],
      "metadata": {
        "id": "UzznzOTP4s53",
        "outputId": "fe5c687a-85d7-42ff-d76e-82472a352bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './gdrive/MyDrive/ROIs_manually_corrected/train_images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-66b8233a0877>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mimage_patches_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_patches_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_image_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# The patches will be read from disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./gdrive/MyDrive/ROIs_manually_corrected/patches\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4d499dfaaea2>\u001b[0m in \u001b[0;36mcreate_image_patches\u001b[0;34m(image_folder, mask_folder, output_folder, patch_size)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mpatch_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0mfenestration_area_thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m     \u001b[0mimage_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0mmask_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './gdrive/MyDrive/ROIs_manually_corrected/train_images'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MVM6cZYK0Oy"
      },
      "source": [
        "# Training setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yt1dWbZiNkm"
      },
      "outputs": [],
      "source": [
        "# # Training parameters\n",
        "# learning_rate = 1e-4\n",
        "# batch_size = 4\n",
        "# num_epochs = 2\n",
        "# num_workers = 0\n",
        "# pin_memory = False # TODO: check\n",
        "# load_model = False\n",
        "\n",
        "# # Define dataloaders for training\n",
        "# data_split = 0.1\n",
        "\n",
        "# # Train and test images, these don't crash the gpu\n",
        "# # image_patches_path = \"./gdrive/MyDrive/ROI_patches/train_img\"\n",
        "# # mask_patches_path = \"./gdrive/MyDrive/ROI_patches/train_mask\"\n",
        "\n",
        "\n",
        "# train_loader, val_loader, train_indices = get_loaders(\n",
        "#     image_patches_path,\n",
        "#     mask_patches_path,\n",
        "#     data_split,\n",
        "#     batch_size,\n",
        "#     num_workers,\n",
        "#     pin_memory\n",
        "# )\n",
        "\n",
        "# model = UNET(in_channels=1, out_channels=1, device=DEVICE, dropout_probability=0.5).to(DEVICE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wandb sweep"
      ],
      "metadata": {
        "id": "WAJp45Xo8p_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_optimizer(model, config, beta1=None, beta2=None):\n",
        "    if config.optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(model.parameters(),\n",
        "                              lr=config.learning_rate,\n",
        "                              weight_decay=config.weight_decay,\n",
        "                              momentum=config.momentum)\n",
        "    elif config.optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(model.parameters(),\n",
        "                               lr=config.learning_rate,\n",
        "                               betas=(config.beta1, config.beta2),\n",
        "                               weight_decay=config.weight_decay)\n",
        "    return optimizer\n",
        "\n",
        "# TRAIN_LOADER = train_loader\n",
        "# VAL_LOADER = val_loader\n",
        "def build_dataloaders(config): # TODO: check if there is a better way to do this\n",
        "    image_patches_path = os.path.join(config.image_patches_path, 'patches_'+ config.image_denoising_methods)\n",
        "    mask_patches_path = os.path.join(config.mask_patches_path, 'patches_'+ config.image_denoising_methods)\n",
        "    image_patches_path = os.path.join(image_patches_path, 'image_patches')\n",
        "    mask_patches_path = os.path.join(mask_patches_path, 'mask_patches')\n",
        "    train_loader, val_loader, _ = get_loaders(\n",
        "        image_patches_path,\n",
        "        mask_patches_path,\n",
        "        config.data_split,\n",
        "        config.batch_size,\n",
        "        num_workers=0,\n",
        "        pin_memory=False\n",
        "    )\n",
        "    return train_loader, val_loader # this is the simplest way to do it, wandb train cannot take any arguments\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, loss_fn):\n",
        "    # model.train()\n",
        "    running_loss = 0\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
        "\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast():\n",
        "            predictions = model(data)\n",
        "            # TODO: change this\n",
        "            # loss = F.nll_loss(torch.sigmoid(predictions), targets)\n",
        "            # loss_fn = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(16))\n",
        "            loss = loss_fn(predictions, targets)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad() # Zero the gradients\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "        if WANDB_CONNECTED or WANDB_LOG:\n",
        "            wandb.log({\"batch loss\": loss.item()})\n",
        "\n",
        "    number_of_batches = batch_idx+1\n",
        "    return running_loss/number_of_batches\n",
        "\n",
        "def build_model(model_name, dropout, loss_func):\n",
        "    in_channels = 1\n",
        "    out_channels = 1\n",
        "    if loss_func != 'bcelog' and loss_func != 'weighted_bce':\n",
        "        out_activation = None\n",
        "    else:\n",
        "        out_activation = 'sigmoid'\n",
        "    if model_name == 'plain_unet':\n",
        "        model = UNET(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                device=DEVICE,\n",
        "                dropout_probability=dropout,\n",
        "                out_activation=out_activation).to(DEVICE)\n",
        "    else:\n",
        "        name_parts = model_name.split('+')\n",
        "        encoder = name_parts[0]\n",
        "        weights = name_parts[1]\n",
        "        model = smp.Unet(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights=weights,\n",
        "                in_channels=in_channels,\n",
        "                classes=out_channels,\n",
        "                out_activation=out_activation,).to(DEVICE)\n",
        "    return model\n",
        "\n",
        "def build_loss_func(func_name):\n",
        "    loss_func = None\n",
        "    if func_name == 'dice':\n",
        "        loss_func = smp.losses.DiceLoss(mode='binary')\n",
        "    elif func_name == 'bcelog':\n",
        "        loss_func = nn.BCEWithLogitsLoss()\n",
        "    elif func_name == 'jaccard':\n",
        "        loss_func = smp.losses.JaccardLoss(mode='binary')\n",
        "    elif func_name == 'weighted_bce':\n",
        "        loss_func = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(4))\n",
        "    elif func_name == 'focal':\n",
        "        loss_func = smp.losses.FocalLoss(mode='binary')\n",
        "    # elif func_name == 'tversky':\n",
        "\n",
        "    # elif func_name == 'hausdorff':\n",
        "\n",
        "    return loss_func\n",
        "\n",
        "def wandb_train(config=None):\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        train_loader, val_loader = build_dataloaders(config)\n",
        "        model = build_model(config.model_type, config.dropout, config.loss_function)\n",
        "        optimizer = build_optimizer(model, config)\n",
        "        loss_fn = build_loss_func(config.loss_function) #nn.BCEWithLogitsLoss(pos_weight = torch.tensor(4))\n",
        "\n",
        "        for epoch in range(config.epochs):\n",
        "            avg_loss = train_epoch(model, train_loader, optimizer, loss_fn)\n",
        "            # print(avg_loss)\n",
        "            metrics = {\"train/loss\": avg_loss, \"train/epoch\": epoch}\n",
        "            val_loss, dice_score = validate_model(model, val_loader, loss_fn)\n",
        "            val_metrics = {\"val/val_loss\": val_loss,\n",
        "                           \"val/dice_score\": dice_score}\n",
        "            wandb.log({**metrics, **val_metrics})\n",
        "\n",
        "class DictObject:\n",
        "    def __init__(self, **entries):\n",
        "        self.__dict__.update(entries)\n",
        "\n",
        "def train(config, model_out_path):\n",
        "    if WANDB_LOG:\n",
        "        wandb.init(\n",
        "            project=\"LSEC_segmentation\",\n",
        "            config=config)\n",
        "        config = wandb.config\n",
        "    else:\n",
        "        config = DictObject(**config)\n",
        "\n",
        "    train_loader, val_loader = build_dataloaders(config)\n",
        "    model = build_model(config.model_type, config.dropout, config.loss_function)\n",
        "    optimizer = build_optimizer(model, config)\n",
        "    loss_fn = build_loss_func(config.loss_function) # nn.BCEWithLogitsLoss(pos_weight = torch.tensor(4))\n",
        "\n",
        "    best_dice_score = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    dice_scores = []\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        model.train()\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, loss_fn)\n",
        "        train_losses.append(train_loss)\n",
        "        val_loss, dice_score = validate_model(model, val_loader, loss_fn)\n",
        "\n",
        "        if dice_score > best_dice_score: # using dice score right now\n",
        "            save_state_dict(model, model_out_path)\n",
        "        best_dice_score = max(dice_score, best_dice_score)\n",
        "\n",
        "        dice_scores.append(dice_score)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f'Dice score: {dice_score}')\n",
        "        view_prediction(val_loader, model, device = DEVICE)\n",
        "        if WANDB_LOG:\n",
        "            wandb.log({\"train/train_loss\": train_loss,\n",
        "                       \"train/epoch\": epoch,\n",
        "                       \"val/val_loss\": val_loss,\n",
        "                       \"val/dice_score\":dice_score,\n",
        "                       })\n",
        "    if WANDB_LOG:\n",
        "        wandb.finish()\n",
        "\n",
        "    return train_losses, val_losses, dice_scores"
      ],
      "metadata": {
        "id": "c6sxUMdmjwo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = \"./gdrive/MyDrive/ROIs_manually_corrected\"\n",
        "data_split = 0.1\n",
        "\n",
        "# wandb sweep config\n",
        "sweep_config = {\n",
        "    'method': 'grid'#'bayes'\n",
        "    }\n",
        "metric = {\n",
        "    'name': 'val/dice_score',\n",
        "    'goal': 'maximize'\n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "parameters_dict = {\n",
        "    'optimizer': {\n",
        "        # 'values': ['adam', 'sgd']\n",
        "        'value': 'sgd'\n",
        "        },\n",
        "    'learning_rate': {\n",
        "        'value': 0.0186,\n",
        "        # # a flat distribution between min and max\n",
        "        # 'distribution': 'uniform',\n",
        "        # 'min': 0.01,\n",
        "        # 'max': 0.02\n",
        "      },\n",
        "    'weight_decay': {\n",
        "        'value': 0.0189,\n",
        "        # 'distribution': 'uniform',\n",
        "        # 'min': 0.01,\n",
        "        # 'max' : 0.02,\n",
        "    },\n",
        "    # sgd parameters\n",
        "    'momentum':{\n",
        "        'value': 0.0722,\n",
        "        # 'distribution': 'uniform',\n",
        "        # 'min': 0.06,\n",
        "        # 'max' : 0.08,\n",
        "    },\n",
        "\n",
        "    'dropout': {\n",
        "        'value': 0.0,\n",
        "        #   'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "        },\n",
        "    'epochs': {\n",
        "        'value': 12\n",
        "        },\n",
        "\n",
        "    # Dataloader params\n",
        "    'image_patches_path': {\n",
        "        'value': output_folder\n",
        "        },\n",
        "    'mask_patches_path': {\n",
        "        'value': output_folder\n",
        "        },\n",
        "    'data_split': {\n",
        "        'value': data_split\n",
        "        },\n",
        "    'batch_size': {\n",
        "        'value': 6,\n",
        "        # # integers between min and max\n",
        "        # # with evenly-distributed logarithms\n",
        "        # 'distribution': 'q_log_uniform_values',\n",
        "        # 'q': 2, # the discrete step of the distribution\n",
        "        # 'min': 4,\n",
        "        # 'max': 8,\n",
        "      },\n",
        "    # Adam parameters\n",
        "    # 'beta1': {\n",
        "    #     'distribution': 'uniform',\n",
        "    #     'min': 0.95,\n",
        "    #     'max' : 0.999,\n",
        "    # },\n",
        "    # 'beta2': {\n",
        "    #     'distribution': 'uniform',\n",
        "    #     'min': 0.95,\n",
        "    #     'max' : 0.999,\n",
        "    # },\n",
        "        # 'fc_layer_size': {\n",
        "    #     'values': [128, 256, 512]\n",
        "    #     },\n",
        "    'image_denoising_methods': {\n",
        "        'value': 'median5',\n",
        "        # 'values': ['clahe+median5', 'med7', 'median5', 'median5+clahe', 'wave1_5+med3', 'wave2_5', 'wave2_5+med5'],#['wavelet', 'wavelet+median', 'advanced median'] # k waveletu jeste pridat ruzne thresholdy\n",
        "    },\n",
        "    'loss_function':{\n",
        "        'values': ['dice', 'jaccard'],#['dice', 'bcelog', 'jaccard', 'weighted_bce', 'focal'],#, 'tversky', 'hausdorff']\n",
        "    },\n",
        "    'model_type':{\n",
        "        # 'values': ['plain_unet', 'resnet34+imagenet', 'resnet50+imagenet', 'inceptionv4+imagenet', 'efficientnet-b7+imagenet', 'resnet18+swsl', 'resnet18+imagenet','vgg11+imagenet'], # not great\n",
        "        # 'values': ['vgg11+imagenet', 'vgg13+imagenet', 'vgg16+imagenet', 'vgg19+imagenet',  'resnet18+ssl','resnet34+imagenet','resnet50+ssl', 'resnext50_32x4d+ssl'], # good\n",
        "        'values': ['vgg13+imagenet', 'vgg16+imagenet', 'vgg19+imagenet',  'resnet18+ssl'], # the best so far\n",
        "    },\n",
        "}\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"LSEC_segmentation\")"
      ],
      "metadata": {
        "id": "Y851Q6gvcd8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1465309a-2fac-4bb6-f03b-8a5abab65636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: m2nazjdl\n",
            "Sweep URL: https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WANDB_CONNECTED = True\n",
        "wandb.agent(sweep_id, wandb_train, count=10)"
      ],
      "metadata": {
        "id": "EXcfFX2wo9P7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4d5f05053be142828ac04cf83a19a555",
            "e2b2c2cceaa745bf965a53709ddf1ea8",
            "3aabfb2dc0004e6bac0e5a1457d15dc2",
            "9037bb2d72e94e0fa3edfdd8d75da417",
            "1a02becf612e421889619b814ded6115",
            "f7a9ec8237444edcba87ab14655dde11",
            "a3a508c59a9d45c1930542a4813a082d",
            "1364e902aabe4950a1eabd86504bdc0c",
            "fdbd14175e6246f3975825aec51d551a",
            "19ea030d4f3c47899633a610b2152735",
            "a3c1135b178c41bd912ae2ffe60fbbcb",
            "bc2ce5cc6bae4fb798d1ef63902a82b3",
            "5e52e57a68b743c99b3db53dd3d9e14d",
            "f6b24b7e74264a46b4594e9e98ea61bf",
            "3965f4f2b70a4df5953263760df0e390",
            "d58f7ef3ce3e4678b78d51195735daa6",
            "7d8d1b82246e4fe0a8e79013a213e51f",
            "c665761af3cf42c5872d7670ce0003a7",
            "5a2b2de35b1b40bf85e6c4d99079fa68",
            "71b3a2cd300d4a7ba3e6a35a92dcb084",
            "863a4575bd574262adccf4c8bb64e8b8",
            "582771a613eb4e23b17edd9ed5ed3700",
            "0e724d671a7540ccb1686dcc15d67348",
            "fdb80c509d3f427da86176f6547d47a6",
            "90e41c31a4f545888db2dfe97c5d3956",
            "70eb985979ad4370bf2d6f1ef16bc866",
            "7c6f8861b3fe4661bb29c512006e8980",
            "695513cfbaf641cd83e9c662198401d8",
            "6a20890162ba4e49b9b203da3a838469",
            "1a3dc5ef9073497ab8f9ae5cc841ffff",
            "ee4516462a6b4997b997f78b495b2f0d",
            "0c8427ef9c88420e9540cc3bc0992d48",
            "3c485fc11d9d4a9796a9c137a773d2d4",
            "6a5024295b034bbfa6b9d10d66cbeadc",
            "b311bf0dcbe341db93dd37ae6c8c0638",
            "c08b5cd02a654259b2419db4f3f7a89c",
            "f59d1369819844c9a33bb7e83717129b",
            "bc4048183c30408b985882e7b6c3006a",
            "bd56143251ae4d50a06195ca638f3aae",
            "1d487f7ec05b4d77b207d594974bdd11",
            "0b14a1176f7e46468bc91f67f4471bfb",
            "7369fd818a6847308cdeb359e9df8d68",
            "7167af3127924f5aaad1203098509ff2",
            "0c71c04f76ad43ceaf7ded2dc837bda4",
            "564d44c15ecf44078783167b61a6e2ee",
            "52e8b45d642a4e54b9324a9bd7430bff",
            "32596e42cc1845568fd541cac3d5b2db",
            "8d19c82993f74a45be6f3d407c771d87",
            "92f6da46da5940829d546d81e069648c",
            "2ea0a3a02c424a72998bdd7a3da1758b",
            "c5e9966488b44089ae4d260543638eeb",
            "7ef02a6303704b06ac931f1de6e70c88",
            "72b88a05d01a49f1b5f9c7d4eb652987",
            "8742698f618641d2ac64af7bbd4bffba",
            "b1f0535469f540b19050d3db083d16bd",
            "d560cf90f9494e588b85eb15ae57b53c",
            "438e8b0ad1cf4f5d9df7eb187dfae2e0",
            "1c8fee49be8c4520b270a3a5f0385635",
            "014282075a2644f297f0736f3d81b8ba",
            "1348a735898e44e6915563ac7f333d58",
            "536b6658c10d4732afa58d22d6444a87",
            "aa87126952a44a6f8a48b33dae6055cc",
            "068a03c7dca74aec8305bc9244b7d67f",
            "5bbb6e4beaa84185af1e7971f6856727"
          ]
        },
        "outputId": "71c439c7-f6b6-4507-d786-5ba5971085d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y7xycjwo with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: median5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: dice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg13+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240305_192009-y7xycjwo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/y7xycjwo' target=\"_blank\">vital-sweep-1</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/y7xycjwo' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/y7xycjwo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.11142346026066956, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d5f05053be142828ac04cf83a19a555"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>██▇██▇▇▇████▇▇▇▆▆▆▆▅▅▆▅▅▃▄▄▃▂▃▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>███▇▇▆▅▃▂▁▁▁</td></tr><tr><td>val/dice_score</td><td>▁▂▂▃▄▆▇█████</td></tr><tr><td>val/val_loss</td><td>███▇▇▆▅▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.1285</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.19684</td></tr><tr><td>val/dice_score</td><td>0.86219</td></tr><tr><td>val/val_loss</td><td>0.18143</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vital-sweep-1</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/y7xycjwo' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/y7xycjwo</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240305_192009-y7xycjwo/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0eth5ep9 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: median5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: dice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg16+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240305_192243-0eth5ep9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/0eth5ep9' target=\"_blank\">dazzling-sweep-2</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/0eth5ep9' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/0eth5ep9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.1113382741289718, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdbd14175e6246f3975825aec51d551a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▇██▇▇██▇▇▇▇▇▆▇▆▆▅▆▆▄▃▄▅▂▃▂▄▂▂▁▂▂▁▁▂▂▁▁▁▂</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>██▇▇▆▅▃▂▂▁▁▁</td></tr><tr><td>val/dice_score</td><td>▁▂▃▄▅▇██████</td></tr><tr><td>val/val_loss</td><td>██▇▇▆▅▃▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.20038</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.18599</td></tr><tr><td>val/dice_score</td><td>0.85841</td></tr><tr><td>val/val_loss</td><td>0.1704</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dazzling-sweep-2</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/0eth5ep9' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/0eth5ep9</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240305_192243-0eth5ep9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: utpgfk6d with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: median5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: dice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg19+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240305_192520-utpgfk6d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/utpgfk6d' target=\"_blank\">apricot-sweep-3</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/utpgfk6d' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/utpgfk6d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.11405650505755145, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d8d1b82246e4fe0a8e79013a213e51f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█████▇▇▇▇▇▇▇▇▆▇▆▆▅▅▄▄▃▃▂▂▂▅▂▂▁▃▁▁▂▁▁▂▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>██▇▇▆▅▃▂▂▁▁▁</td></tr><tr><td>val/dice_score</td><td>▁▂▃▄▅▇██████</td></tr><tr><td>val/val_loss</td><td>███▇▆▅▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.17018</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.18746</td></tr><tr><td>val/dice_score</td><td>0.85669</td></tr><tr><td>val/val_loss</td><td>0.17364</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">apricot-sweep-3</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/utpgfk6d' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/utpgfk6d</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240305_192520-utpgfk6d/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oqx3vjwn with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: median5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: dice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: resnet18+ssl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240305_192813-oqx3vjwn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/oqx3vjwn' target=\"_blank\">devout-sweep-4</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/oqx3vjwn' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/oqx3vjwn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.1140763997906855, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90e41c31a4f545888db2dfe97c5d3956"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▇█▇▇▇▇▇█▇▇▆▇▇▇▆▆▇▆▇▆▅▆▅▃▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>███▇▇▇▆▄▃▂▁▁</td></tr><tr><td>val/dice_score</td><td>▁▂▃▄▄▅▆▇▇██▇</td></tr><tr><td>val/val_loss</td><td>███▇▇▆▅▄▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.21452</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.22061</td></tr><tr><td>val/dice_score</td><td>0.73779</td></tr><tr><td>val/val_loss</td><td>0.28229</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">devout-sweep-4</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/oqx3vjwn' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/oqx3vjwn</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240305_192813-oqx3vjwn/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w9wsw8nl with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: median5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: jaccard\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg13+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240305_192948-w9wsw8nl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/w9wsw8nl' target=\"_blank\">dark-sweep-5</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/w9wsw8nl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/w9wsw8nl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c485fc11d9d4a9796a9c137a773d2d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>██▇▇▇█▇▇▇█▇▇█▆▇▇▇▆█▇▅▆▆▆▆▆▆▇▆▅▄▅▆▅▅▂▃▆▂▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>████▇▇▇▇▆▅▄▁</td></tr><tr><td>val/dice_score</td><td>▁▁▁▂▂▃▃▄▅▆██</td></tr><tr><td>val/val_loss</td><td>█████▇▇▇▆▅▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.57231</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.59979</td></tr><tr><td>val/dice_score</td><td>0.82492</td></tr><tr><td>val/val_loss</td><td>0.51489</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dark-sweep-5</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/w9wsw8nl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/w9wsw8nl</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240305_192948-w9wsw8nl/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: buxdapqh with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: median5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: jaccard\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg16+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240305_193209-buxdapqh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/buxdapqh' target=\"_blank\">eager-sweep-6</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/buxdapqh' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/buxdapqh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.11142346026066956, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b14a1176f7e46468bc91f67f4471bfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█████▇██▇▇▇▇▇▆█▇▇▆▆▆▆▅▆▄▄▃▄▃▂▃▁▂▂▂▂▂▃▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>███▇▇▆▅▄▂▂▁▁</td></tr><tr><td>val/dice_score</td><td>▁▂▃▄▅▆▇██▇██</td></tr><tr><td>val/val_loss</td><td>███▇▇▆▅▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.30574</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.31463</td></tr><tr><td>val/dice_score</td><td>0.86361</td></tr><tr><td>val/val_loss</td><td>0.2856</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">eager-sweep-6</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/buxdapqh' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/buxdapqh</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240305_193209-buxdapqh/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c61skysj with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: median5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: jaccard\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg19+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240305_193446-c61skysj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/c61skysj' target=\"_blank\">lunar-sweep-7</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/c61skysj' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/c61skysj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92f6da46da5940829d546d81e069648c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>██████████▇██▇█▇▇▇▆▆▇▇▆▆▆▆▅▄▅▃▄▂▂▁▂▂▂▃▁▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>███▇▇▇▇▆▄▃▁▁</td></tr><tr><td>val/dice_score</td><td>▁▂▃▄▄▅▆▇▇███</td></tr><tr><td>val/val_loss</td><td>███▇▇▇▆▅▄▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.2983</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.34194</td></tr><tr><td>val/dice_score</td><td>0.8624</td></tr><tr><td>val/val_loss</td><td>0.29897</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lunar-sweep-7</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/c61skysj' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/c61skysj</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240305_193446-c61skysj/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2o1lscht with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: median5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: jaccard\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/ROIs_manually_corrected\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: resnet18+ssl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240305_193737-2o1lscht</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/2o1lscht' target=\"_blank\">glowing-sweep-8</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/m2nazjdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/2o1lscht' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/2o1lscht</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded\\r'), FloatProgress(value=0.1139693058946634, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "438e8b0ad1cf4f5d9df7eb187dfae2e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>██▇▅▇▆▇▇▆▇█▆▆▇▅▆▆▆▇▅▆▅▅▅█▅▆▄▆▆▆▃▄▅▃▄▄▄▁▂</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>██▇▇▇▆▆▅▅▄▃▁</td></tr><tr><td>val/dice_score</td><td>▁▂▂▂▃▃▄▅▅▆▇█</td></tr><tr><td>val/val_loss</td><td>██▇▇▆▆▆▅▅▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.84198</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.84077</td></tr><tr><td>val/dice_score</td><td>0.571</td></tr><tr><td>val/val_loss</td><td>0.83442</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glowing-sweep-8</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/2o1lscht' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/2o1lscht</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240305_193737-2o1lscht/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "KPwZ2wIG8htJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wewnAeW8FnOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOAD_MODEL = False\n",
        "WANDB_CONNECTED = False\n",
        "WANDB_LOG = True\n",
        "image_patches_path = \"./gdrive/MyDrive/ROIs_manually_corrected\" # + image_denoising_methods\n",
        "mask_patches_path = \"./gdrive/MyDrive/ROIs_manually_corrected\"\n",
        "\n",
        "config = {\n",
        "    'batch_size' : 6,\n",
        "    'dropout' : 0.0,\n",
        "    'optimizer' : 'sgd',\n",
        "    'num_epochs' : 30,\n",
        "    'learning_rate' : 0.0186,\n",
        "    'weight_decay' : 0.0189,\n",
        "    'momentum' : 0.0722,\n",
        "    'data_split' : 0.1,\n",
        "    'image_patches_path': image_patches_path,\n",
        "    'mask_patches_path': mask_patches_path,\n",
        "    'image_denoising_methods': 'median5',\n",
        "    'loss_function': 'dice',\n",
        "    'model_type': 'vgg16+imagenet',\n",
        "}\n"
      ],
      "metadata": {
        "id": "-0Al6T1fdX_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_MODEL:\n",
        "    model = UNET(in_channels=1, out_channels=1, device=DEVICE, dropout_probability=config['dropout'], activations = 'ReLU', out_activation=None).to(DEVICE)\n",
        "    load_state_dict(model, model_path)\n",
        "else:\n",
        "    WANDB_LOG = True\n",
        "    train_losses, val_losses, dice_scores = train(config, model_path)"
      ],
      "metadata": {
        "id": "IaxEOPPRbMjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICjg9JWmLAo9"
      },
      "source": [
        "# Training evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ay9PlVUxpq0"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Time')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLh2DOF_z7En"
      },
      "outputs": [],
      "source": [
        "plt.plot(dice_scores, label='Dice score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Dice score')\n",
        "plt.title('Dice Score Over Time')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLmWmnwWbCaZ"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtZyUqY3bByz"
      },
      "outputs": [],
      "source": [
        "# Inference on full images\n",
        "test_image_path = \"./gdrive/MyDrive/lsec_test/old11_CA150_NE_01.tif\"\n",
        "test_mask_path = \"./gdrive/MyDrive/lsec_test/old11_CA150_NE_01_original_mask.tif\"\n",
        "\n",
        "output_folder = \"./gdrive/MyDrive/lsec_test\"\n",
        "# model = UNET(in_channels=1, out_channels=1, device=DEVICE, dropout_probability=config['dropout'], activation=None).to(DEVICE)\n",
        "model = build_model('vgg16+imagenet', 0.0, 'dice')\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "out_mask_path = inference_on_image_with_overlap(model, test_image_path, output_folder)\n",
        "merge_original_mask(test_image_path, test_mask_path, output_folder)\n",
        "merge_masks(out_mask_path, test_mask_path, output_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyXUfWY3KtHa"
      },
      "source": [
        "# Bioimageio stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0UWu17Y2fM4"
      },
      "outputs": [],
      "source": [
        "# !pip install \"bioimageio.core>=0.5,<0.6\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7SgQQqm3K8q"
      },
      "outputs": [],
      "source": [
        "# @torch.jit.ignore\n",
        "# def call_np(tensor) -> torch.Tensor:\n",
        "#   na = tensor.numpy()\n",
        "#   # Interesting stuff here\n",
        "#   tt = torch.tensor(na)\n",
        "#   return tt\n",
        "\n",
        "# class MyModule(nn.Module):\n",
        "#     @torch.jit.export\n",
        "#     def forward(self, tensor):\n",
        "#         done = call_np(tensor)\n",
        "#         print (done)\n",
        "\n",
        "# scripted_module = torch.jit.script(MyModule())\n",
        "# print(scripted_module.forward.graph)\n",
        "# empty_tensor = torch.empty(3, 4)\n",
        "# scripted_module.forward(empty_tensor)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2FcX34DwhgX"
      },
      "outputs": [],
      "source": [
        "# import torchvision.transforms as transforms\n",
        "# import numpy as np\n",
        "\n",
        "# @torch.jit.ignore\n",
        "# def denoise_image(tensor) -> torch.Tensor:\n",
        "#   na = tensor.numpy()\n",
        "#   # Interesting stuff here\n",
        "#   tt = torch.tensor(na)\n",
        "#   return tt\n",
        "\n",
        "# class FunctionWrapper(nn.Module):\n",
        "#   def __init__(self, model):\n",
        "#     super(FunctionWrapper, self).__init__()\n",
        "#     self.model = model\n",
        "\n",
        "#     @torch.jit.export\n",
        "#     def forward(self, tensor):\n",
        "#         denoised = denoise_image(tensor)\n",
        "#         return self.model(denoised)\n",
        "\n",
        "\n",
        "\n",
        "# device = torch.device('cpu')\n",
        "# model = UNET(in_channels=1, out_channels=1, device='cpu')\n",
        "# model.load_state_dict(torch.load(biomodel_path, map_location=device))\n",
        "# # model.to(device=device)\n",
        "# model = torch.jit.script(model)\n",
        "# # wrapper = FunctionWrapper(model)\n",
        "# wrapper.to(device=device)\n",
        "# # wrapper = PreprocessingWrapper(denoise, model)\n",
        "# # model = torch.jit.script(wrapper)\n",
        "# #\n",
        "# model.eval()\n",
        "# torchscript_weights_path = os.path.join(biomodel_folder, 'torchscript_weights.pt')\n",
        "# torch.jit.save(model, torchscript_weights_path)\n",
        "\n",
        "# preprocessing=[[{\"name\": \"scale_range\",\n",
        "#                  \"kwargs\": {\"axes\": \"xy\",\n",
        "#                           #  \"min_percentile\": min_percentile,\n",
        "#                             # \"max_percentile\": max_percentile,\n",
        "#                             \"mode\": \"per_sample\"\n",
        "#                             }}]]\n",
        "\n",
        "# threshold = 0.5\n",
        "# postprocessing = [[{\"name\": \"binarize\", \"kwargs\": {\"threshold\": threshold}}]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DU4m7qIy7rt"
      },
      "outputs": [],
      "source": [
        "# input = np.random.rand(1, 1, 512, 512).astype(\"float32\")  # an example input\n",
        "# test_inputs = os.path.join(biomodel_folder, \"test-input.npy\")\n",
        "# test_outputs = os.path.join(biomodel_folder, \"test-output.npy\")\n",
        "# np.save(test_inputs, input)\n",
        "# with torch.no_grad():\n",
        "#   output = model(torch.from_numpy(input)).cpu().numpy() # copy to cpu(is on gpu because of jit.script)\n",
        "#   output = output > threshold\n",
        "# np.save(test_outputs, output)\n",
        "\n",
        "# print(input.shape)\n",
        "# print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaqoBNRJiNKg"
      },
      "outputs": [],
      "source": [
        "# # create markdown documentation for your model\n",
        "# # this should describe how the model was trained, (and on which data)\n",
        "# # and also what to take into consideration when running the model, especially how to validate the model\n",
        "# # here, we just create a stub documentation\n",
        "# doc_path = os.path.join(biomodel_folder, \"doc.md\")\n",
        "# with open(doc_path, \"w\") as f:\n",
        "#     f.write(\"# My First Model\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfMXWAziiNGI"
      },
      "outputs": [],
      "source": [
        "# from bioimageio.core.build_spec import build_model\n",
        "# import torch\n",
        "# # now we can use the build_model function to create the zipped package.\n",
        "# # it takes the path to the weights and data we have just created, as well as additional information\n",
        "# # that will be used to add metadata to the rdf.yaml file in the model zip\n",
        "# # we only use a subset of the available options here, please refer to the advanced examples and to the\n",
        "# # function signature of build_model in order to get an overview of the full functionality\n",
        "# build_model(\n",
        "#     # the weight file and the type of the weights\n",
        "#     weight_uri= torchscript_weights_path,\n",
        "#     weight_type=\"torchscript\",\n",
        "#     # the test input and output data as well as the description of the tensors\n",
        "#     # these are passed as list because we support multiple inputs / outputs per model\n",
        "#     test_inputs=[test_inputs],\n",
        "#     test_outputs=[test_outputs],\n",
        "#     input_axes=[\"bcyx\"],\n",
        "#     output_axes=[\"bcyx\"],\n",
        "#     # where to save the model zip, how to call the model and a short description of it\n",
        "#     output_path=os.path.join(biomodel_folder,\"model.zip\"),\n",
        "#     name=\"MyFirstModel\",\n",
        "#     description=\"a fancy new model\",\n",
        "#     # additional metadata about authors, licenses, citation etc.\n",
        "#     authors=[{\"name\": \"Gizmo\"}],\n",
        "#     license=\"CC-BY-4.0\",\n",
        "#     documentation=doc_path,\n",
        "#     tags=[\"nucleus-segmentation\"],  # the tags are used to make models more findable on the website\n",
        "#     cite=[{\"text\": \"Gizmo et al.\", \"doi\": \"10.1002/xyzacab123\"}],\n",
        "#     pytorch_version=torch.__version__,\n",
        "#     preprocessing=preprocessing,\n",
        "#     postprocessing=postprocessing\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2RJJ5WriND4"
      },
      "outputs": [],
      "source": [
        "# # finally, we test that the expected outptus are reproduced when running the model.\n",
        "# # the 'test_model' function runs this test.\n",
        "# # it will output a list of dictionaries. each dict gives the status of a different test that is being run\n",
        "# # if all of them contain \"status\": \"passed\" then all tests were successful\n",
        "# from bioimageio.core.resource_tests import test_model\n",
        "# import bioimageio.core\n",
        "# my_model = bioimageio.core.load_resource_description(os.path.join(biomodel_folder,\"model.zip\"))\n",
        "# test_model(my_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "oyXUfWY3KtHa"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d5f05053be142828ac04cf83a19a555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2b2c2cceaa745bf965a53709ddf1ea8",
              "IPY_MODEL_3aabfb2dc0004e6bac0e5a1457d15dc2"
            ],
            "layout": "IPY_MODEL_9037bb2d72e94e0fa3edfdd8d75da417"
          }
        },
        "e2b2c2cceaa745bf965a53709ddf1ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a02becf612e421889619b814ded6115",
            "placeholder": "​",
            "style": "IPY_MODEL_f7a9ec8237444edcba87ab14655dde11",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "3aabfb2dc0004e6bac0e5a1457d15dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3a508c59a9d45c1930542a4813a082d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1364e902aabe4950a1eabd86504bdc0c",
            "value": 1
          }
        },
        "9037bb2d72e94e0fa3edfdd8d75da417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a02becf612e421889619b814ded6115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7a9ec8237444edcba87ab14655dde11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3a508c59a9d45c1930542a4813a082d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1364e902aabe4950a1eabd86504bdc0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdbd14175e6246f3975825aec51d551a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19ea030d4f3c47899633a610b2152735",
              "IPY_MODEL_a3c1135b178c41bd912ae2ffe60fbbcb"
            ],
            "layout": "IPY_MODEL_bc2ce5cc6bae4fb798d1ef63902a82b3"
          }
        },
        "19ea030d4f3c47899633a610b2152735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e52e57a68b743c99b3db53dd3d9e14d",
            "placeholder": "​",
            "style": "IPY_MODEL_f6b24b7e74264a46b4594e9e98ea61bf",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "a3c1135b178c41bd912ae2ffe60fbbcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3965f4f2b70a4df5953263760df0e390",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d58f7ef3ce3e4678b78d51195735daa6",
            "value": 1
          }
        },
        "bc2ce5cc6bae4fb798d1ef63902a82b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e52e57a68b743c99b3db53dd3d9e14d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b24b7e74264a46b4594e9e98ea61bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3965f4f2b70a4df5953263760df0e390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d58f7ef3ce3e4678b78d51195735daa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d8d1b82246e4fe0a8e79013a213e51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c665761af3cf42c5872d7670ce0003a7",
              "IPY_MODEL_5a2b2de35b1b40bf85e6c4d99079fa68"
            ],
            "layout": "IPY_MODEL_71b3a2cd300d4a7ba3e6a35a92dcb084"
          }
        },
        "c665761af3cf42c5872d7670ce0003a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_863a4575bd574262adccf4c8bb64e8b8",
            "placeholder": "​",
            "style": "IPY_MODEL_582771a613eb4e23b17edd9ed5ed3700",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "5a2b2de35b1b40bf85e6c4d99079fa68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e724d671a7540ccb1686dcc15d67348",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdb80c509d3f427da86176f6547d47a6",
            "value": 1
          }
        },
        "71b3a2cd300d4a7ba3e6a35a92dcb084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "863a4575bd574262adccf4c8bb64e8b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582771a613eb4e23b17edd9ed5ed3700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e724d671a7540ccb1686dcc15d67348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb80c509d3f427da86176f6547d47a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90e41c31a4f545888db2dfe97c5d3956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70eb985979ad4370bf2d6f1ef16bc866",
              "IPY_MODEL_7c6f8861b3fe4661bb29c512006e8980"
            ],
            "layout": "IPY_MODEL_695513cfbaf641cd83e9c662198401d8"
          }
        },
        "70eb985979ad4370bf2d6f1ef16bc866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a20890162ba4e49b9b203da3a838469",
            "placeholder": "​",
            "style": "IPY_MODEL_1a3dc5ef9073497ab8f9ae5cc841ffff",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "7c6f8861b3fe4661bb29c512006e8980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee4516462a6b4997b997f78b495b2f0d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c8427ef9c88420e9540cc3bc0992d48",
            "value": 1
          }
        },
        "695513cfbaf641cd83e9c662198401d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a20890162ba4e49b9b203da3a838469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a3dc5ef9073497ab8f9ae5cc841ffff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee4516462a6b4997b997f78b495b2f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c8427ef9c88420e9540cc3bc0992d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c485fc11d9d4a9796a9c137a773d2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a5024295b034bbfa6b9d10d66cbeadc",
              "IPY_MODEL_b311bf0dcbe341db93dd37ae6c8c0638"
            ],
            "layout": "IPY_MODEL_c08b5cd02a654259b2419db4f3f7a89c"
          }
        },
        "6a5024295b034bbfa6b9d10d66cbeadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f59d1369819844c9a33bb7e83717129b",
            "placeholder": "​",
            "style": "IPY_MODEL_bc4048183c30408b985882e7b6c3006a",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "b311bf0dcbe341db93dd37ae6c8c0638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd56143251ae4d50a06195ca638f3aae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d487f7ec05b4d77b207d594974bdd11",
            "value": 1
          }
        },
        "c08b5cd02a654259b2419db4f3f7a89c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f59d1369819844c9a33bb7e83717129b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc4048183c30408b985882e7b6c3006a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd56143251ae4d50a06195ca638f3aae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d487f7ec05b4d77b207d594974bdd11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b14a1176f7e46468bc91f67f4471bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7369fd818a6847308cdeb359e9df8d68",
              "IPY_MODEL_7167af3127924f5aaad1203098509ff2"
            ],
            "layout": "IPY_MODEL_0c71c04f76ad43ceaf7ded2dc837bda4"
          }
        },
        "7369fd818a6847308cdeb359e9df8d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_564d44c15ecf44078783167b61a6e2ee",
            "placeholder": "​",
            "style": "IPY_MODEL_52e8b45d642a4e54b9324a9bd7430bff",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "7167af3127924f5aaad1203098509ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32596e42cc1845568fd541cac3d5b2db",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d19c82993f74a45be6f3d407c771d87",
            "value": 1
          }
        },
        "0c71c04f76ad43ceaf7ded2dc837bda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "564d44c15ecf44078783167b61a6e2ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e8b45d642a4e54b9324a9bd7430bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32596e42cc1845568fd541cac3d5b2db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d19c82993f74a45be6f3d407c771d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92f6da46da5940829d546d81e069648c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ea0a3a02c424a72998bdd7a3da1758b",
              "IPY_MODEL_c5e9966488b44089ae4d260543638eeb"
            ],
            "layout": "IPY_MODEL_7ef02a6303704b06ac931f1de6e70c88"
          }
        },
        "2ea0a3a02c424a72998bdd7a3da1758b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72b88a05d01a49f1b5f9c7d4eb652987",
            "placeholder": "​",
            "style": "IPY_MODEL_8742698f618641d2ac64af7bbd4bffba",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "c5e9966488b44089ae4d260543638eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1f0535469f540b19050d3db083d16bd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d560cf90f9494e588b85eb15ae57b53c",
            "value": 1
          }
        },
        "7ef02a6303704b06ac931f1de6e70c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b88a05d01a49f1b5f9c7d4eb652987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8742698f618641d2ac64af7bbd4bffba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1f0535469f540b19050d3db083d16bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d560cf90f9494e588b85eb15ae57b53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "438e8b0ad1cf4f5d9df7eb187dfae2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c8fee49be8c4520b270a3a5f0385635",
              "IPY_MODEL_014282075a2644f297f0736f3d81b8ba"
            ],
            "layout": "IPY_MODEL_1348a735898e44e6915563ac7f333d58"
          }
        },
        "1c8fee49be8c4520b270a3a5f0385635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_536b6658c10d4732afa58d22d6444a87",
            "placeholder": "​",
            "style": "IPY_MODEL_aa87126952a44a6f8a48b33dae6055cc",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "014282075a2644f297f0736f3d81b8ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_068a03c7dca74aec8305bc9244b7d67f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bbb6e4beaa84185af1e7971f6856727",
            "value": 1
          }
        },
        "1348a735898e44e6915563ac7f333d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536b6658c10d4732afa58d22d6444a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa87126952a44a6f8a48b33dae6055cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "068a03c7dca74aec8305bc9244b7d67f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bbb6e4beaa84185af1e7971f6856727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}