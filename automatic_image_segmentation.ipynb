{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marketakvasova/LSEC_segmentation/blob/main/automatic_image_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXBX4DqRE9h2"
      },
      "source": [
        "# **Automatic segmentation of electron microscope images**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is intended for training a neural network for the task of binary segmentation of fenestrations of Liver sinusoidal entdothelial cells (LSECS)."
      ],
      "metadata": {
        "id": "-aHjwiD8IkQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use this notebook"
      ],
      "metadata": {
        "id": "J-Z80u6TN3Uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train a network, first connect to a GPU (**Runtime -> Change runtime time -> Hardware accelerator -> GPU**).\n",
        "\n",
        "If you are using a pretrained network for inference and not training, being connected only to a **CPU** is slower, but possible."
      ],
      "metadata": {
        "id": "NUZeORlUN_LS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook works with data saved on your Google Drive. Network training requires pairs of images and their corresponding masks saved in two diferent folders. The image-mask pairs don't need to be named exactly the same, but they should correspond when sorted alphabetically."
      ],
      "metadata": {
        "id": "-gq1-hflPdMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "#@markdown ##**Run this cell to connect to Google Drive**\n",
        "#@markdown A new window will open where you will be able to connect.\n",
        "\n",
        "#@markdown When you are connected, you can see your Drive content in the left sidebar under **Files**.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "LHteKyDySYvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9be8e6-4fb5-46ad-d938-a588b830c489"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0RgOiEHFZyI"
      },
      "source": [
        "# **1. Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N5QvbqMfiA4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9600f8a-742f-457b-c5d4-02e915eb71eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torchmetrics-1.3.2\n",
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.17.1+cu121)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.9.2 (from segmentation-models-pytorch)\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.2.1+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.31.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (24.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=0978e488faabae467b1fb6f0396a5e3cc63ace48e430e68ba4137f8c427d2c00\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=ac5f887d2b65d8098478f749649bcebc94d72737f810f5a622a7cc820beded76\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!pip install wandb\n",
        "!pip install torchmetrics\n",
        "!pip install segmentation-models-pytorch\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from torchmetrics.classification import Dice, BinaryJaccardIndex\n",
        "import os\n",
        "from google.colab import drive\n",
        "import torch.cuda\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "import shutil\n",
        "import cv2 as cv\n",
        "from numpy.lib.stride_tricks import as_strided\n",
        "import pywt\n",
        "from scipy.stats import norm\n",
        "from google.colab.patches import cv2_imshow\n",
        "import gc\n",
        "import wandb\n",
        "from numba import njit\n",
        "from scipy.signal import convolve2d\n",
        "import math\n",
        "\n",
        "# gc.collect()\n",
        "drive.mount('/content/gdrive')\n",
        "model_folder = \"./gdrive/MyDrive/ROI_patches/my_model\"\n",
        "os.makedirs(model_folder, exist_ok=True)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # TODO: do not even try this, if the gpu is not connected\n",
        "print(DEVICE)\n",
        "biomodel_folder = os.path.join(model_folder, \"bioimageio_model\")\n",
        "biomodel_path = os.path.join(biomodel_folder, \"weights.pt\")\n",
        "os.makedirs(biomodel_folder, exist_ok=True)\n",
        "LOAD_TRAINED_MODEL = False\n",
        "model_path = os.path.join(model_folder,\"my_checkpoint.pth.tar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om_n1-_pGegM"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M0WZPlvMjs0"
      },
      "source": [
        "## Data utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "G5gyUZlsiNvB"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transofrm=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transofrm\n",
        "        self.images = sorted([f for f in os.listdir(self.image_dir) if os.path.isfile(os.path.join(self.image_dir, f))])\n",
        "        self.masks = sorted([f for f in os.listdir(self.mask_dir) if os.path.isfile(os.path.join(self.mask_dir, f))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.image_dir, self.images[index])\n",
        "        mask_path = os.path.join(self.mask_dir, self.masks[index]) # mask and image need to be called the same\n",
        "        image = cv.imread(img_path, cv.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "        mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "        # mask[mask == 255.0] = 1\n",
        "        mask /= 255\n",
        "        return image, mask\n",
        "\n",
        "class TransformDataset(Dataset):\n",
        "    def __init__(self, dataset, transform):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, mask = self.dataset[index]\n",
        "        augmentations = self.transform(image=image, mask=mask)\n",
        "        image = augmentations[\"image\"]\n",
        "        mask = augmentations[\"mask\"]\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "def get_loaders(img_dir, mask_dir, split, batch_size, num_workers=4, pin_memory=True): # TODO: check these parameters\n",
        "    data = MyDataset(\n",
        "        image_dir=img_dir,\n",
        "        mask_dir=mask_dir,\n",
        "        transofrm=None\n",
        "    )\n",
        "\n",
        "    train_transform, val_transform = get_transforms()\n",
        "\n",
        "    train_indices, test_indices = train_test_split(\n",
        "        range(len(data)),\n",
        "        test_size=split,\n",
        "        random_state=42\n",
        "    )\n",
        "    train_data = TransformDataset(Subset(data, train_indices), train_transform)\n",
        "    val_data = TransformDataset(Subset(data, test_indices), val_transform)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_data,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, train_indices\n",
        "\n",
        "def get_transforms():\n",
        "    train_transform = A.Compose( # TODO: background(preprocessing?), intensity\n",
        "        [\n",
        "            A.Rotate(limit=35, p=1.0),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            # A.Affine(shear=(0.5,1)),\n",
        "            # A.Affine(scale=(-10, 10)),\n",
        "            A.Normalize(\n",
        "                mean = 0.0,\n",
        "                std = 1.0,\n",
        "                max_pixel_value=255.0, # normalization to [0, 1]\n",
        "            ),\n",
        "            ToTensorV2()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    val_transform = A.Compose(\n",
        "        [\n",
        "            A.Normalize(\n",
        "                mean = 0.0,\n",
        "                std = 1.0,\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2()\n",
        "        ]\n",
        "    )\n",
        "    return train_transform, val_transform\n",
        "\n",
        "# test_transform = A.Compose(\n",
        "#     [\n",
        "#     A.Normalize(\n",
        "#       mean = 0.0,\n",
        "#       std = 1.0,\n",
        "#       max_pixel_value=255.0,\n",
        "#     ),\n",
        "#         ToTensorV2()\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # Add more transformations if needed\n",
        "])\n",
        "\n",
        "\n",
        "def merge_images(image, mask):\n",
        "    merge = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
        "    merge[:, :, 0] = image # B channel (0, 1, 2) = (B, G, R)\n",
        "    merge[:, :, 2] = image # R channel\n",
        "    merge[:, :, 1] = mask # G channel\n",
        "    merge[:, :, 2][mask == 255.0] = 255 # R channel\n",
        "    merge = merge.astype('uint8')\n",
        "    return merge\n",
        "\n",
        "\n",
        "def merge_original_mask(image_path, mask_path, output_folder):\n",
        "    image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "    mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
        "    merge = merge_images(image, mask)\n",
        "    filename_ext = os.path.basename(image_path)\n",
        "    filename, ext = os.path.splitext(filename_ext)\n",
        "    cv.imwrite(os.path.join(output_folder, filename+\"_original_mask_merge\"+ext), merge)\n",
        "\n",
        "\n",
        "def merge_masks(mask1_path, mask2_path, output_folder):\n",
        "    mask1 = cv.imread(mask1_path, cv.IMREAD_GRAYSCALE)\n",
        "    mask2 = cv.imread(mask2_path, cv.IMREAD_GRAYSCALE)\n",
        "    # merge = merge_images(image, mask)\n",
        "    merge = np.zeros((mask1.shape[0], mask1.shape[1], 3))\n",
        "\n",
        "    merge[:, :, 1][mask1 == 255.0] = 255\n",
        "    merge[:, :, 2][mask2 == 255.0] = 255\n",
        "\n",
        "    filename_ext = os.path.basename(mask1_path)\n",
        "    filename, ext = os.path.splitext(filename_ext)\n",
        "    cv.imwrite(os.path.join(output_folder, filename+\"_mask_compare\"+ext), merge)\n",
        "\n",
        "\n",
        "def create_weighting_patches(patch_size, edge_size):\n",
        "    patch = np.ones((patch_size, patch_size), dtype=float)\n",
        "\n",
        "    # Calculate the linear decrease values\n",
        "    decrease_values = np.linspace(1, 0, num=edge_size)\n",
        "    decrease_values = np.tile(decrease_values, (patch_size, 1))\n",
        "    increase_values = np.linspace(0, 1, num=edge_size)\n",
        "    increase_values = np.tile(increase_values, (patch_size, 1))\n",
        "\n",
        "    # Middle patch\n",
        "    # Apply linear decrease to all four edges\n",
        "    middle = patch.copy()\n",
        "    middle[:, 0:edge_size] *= increase_values\n",
        "    middle[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    middle[0:edge_size, :] *= increase_values.T\n",
        "    middle[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((middle*255).astype(np.uint8))\n",
        "\n",
        "    # Left\n",
        "    left = patch.copy()\n",
        "    left[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    left[0:edge_size, :] *= increase_values.T\n",
        "    left[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((left*255).astype(np.uint8))\n",
        "\n",
        "    # Right\n",
        "    right = patch.copy()\n",
        "    right[:, 0:edge_size] *= increase_values\n",
        "    right[0:edge_size, :] *= increase_values.T\n",
        "    right[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((right*255).astype(np.uint8))\n",
        "\n",
        "    # Top\n",
        "    top = patch.copy()\n",
        "    top[:, 0:edge_size] *= increase_values\n",
        "    top[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    top[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((top*255).astype(np.uint8))\n",
        "\n",
        "    # Bottom\n",
        "    bottom = patch.copy()\n",
        "    bottom[:, 0:edge_size] *= increase_values\n",
        "    bottom[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    bottom[0:edge_size, :] *= increase_values.T\n",
        "    # cv2_imshow((bottom*255).astype(np.uint8))\n",
        "\n",
        "    # Left Top edge\n",
        "    top_left = patch.copy()\n",
        "    top_left[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    top_left[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((top_left*255).astype(np.uint8))\n",
        "\n",
        "    # Right top edge\n",
        "    top_right = patch.copy()\n",
        "    top_right[:, 0:edge_size] *= increase_values\n",
        "    top_right[patch_size-edge_size:patch_size, :] *= decrease_values.T\n",
        "    # cv2_imshow((top_right*255).astype(np.uint8))\n",
        "\n",
        "    # Left bottom edge\n",
        "    bottom_left = patch.copy()\n",
        "    bottom_left[:, patch_size-edge_size:patch_size] *= decrease_values\n",
        "    bottom_left[0:edge_size, :] *= increase_values.T\n",
        "    # cv2_imshow((bottom_left*255).astype(np.uint8))\n",
        "\n",
        "    # Right Bottom edge\n",
        "    bottom_right = patch.copy()\n",
        "    bottom_right[:, 0:edge_size] *= increase_values\n",
        "    bottom_right[0:edge_size, :] *= increase_values.T\n",
        "    # cv2_imshow((bottom_right*255).astype(np.uint8))\n",
        "\n",
        "    return middle, top_left, top, top_right, right, bottom_right, bottom, bottom_left, left\n",
        "\n",
        "\n",
        "def add_mirrored_border(image, border_size, window_size):\n",
        "    height, width = image.shape\n",
        "\n",
        "    bottom_edge = window_size - ((height + border_size) % (window_size - border_size))\n",
        "    right_edge = window_size - ((width + border_size) % (window_size - border_size))\n",
        "\n",
        "    top_border = np.flipud(image[0:border_size, :])\n",
        "    bottom_border = np.flipud(image[height - border_size:height, :])\n",
        "    bottom_zeros = np.zeros((bottom_edge-border_size, width), dtype = image.dtype)\n",
        "    top_bottom_mirrored = np.vstack((top_border, image, bottom_border, bottom_zeros))\n",
        "\n",
        "    left_border = np.fliplr(top_bottom_mirrored[:, 0:border_size])\n",
        "    right_border = np.fliplr(top_bottom_mirrored[:, width - border_size:width])\n",
        "    right_zeros = np.zeros((top_bottom_mirrored.shape[0], right_edge-border_size), dtype = image.dtype)\n",
        "    mirrored_image = np.hstack((left_border, top_bottom_mirrored, right_border, right_zeros))\n",
        "    return mirrored_image\n",
        "\n",
        "def inference_on_image_with_overlap(model, image_path, output_folder):\n",
        "    window_size = 512\n",
        "    oh, ow = 50, 50\n",
        "    # out_crop =\n",
        "    input_image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "    input_image = preprocess_image(input_image)\n",
        "    image_height, image_width = input_image.shape\n",
        "    original_height, original_width = image_height, image_width\n",
        "\n",
        "    # bottom_edge = (image_height + oh) % (window_size - oh)\n",
        "    # right_edge = (image_height + ow) % (window_size - ow)\n",
        "\n",
        "    mirrored_image = add_mirrored_border(input_image, oh, window_size)\n",
        "    # print(mirrored_image.shape)\n",
        "    image_height, image_width = mirrored_image.shape\n",
        "\n",
        "\n",
        "    weights = np.zeros((image_height, image_width))\n",
        "    # tryout = np.zeros((image_height, image_width))\n",
        "    output_probs = np.zeros((image_height, image_width))\n",
        "    output_mask = np.zeros((image_height, image_width))\n",
        "    middle, top_left, top, top_right, right, bottom_right, bottom, bottom_left, left = create_weighting_patches(window_size, oh)\n",
        "\n",
        "    for x in range(0, image_height-window_size+1, window_size - oh):\n",
        "        for y in range(0, image_width-window_size+1, window_size - ow):\n",
        "            # Choose weighting window\n",
        "            # print(x, y)\n",
        "            if x == 0:\n",
        "                if y == 0:\n",
        "                    # if original_height != window_size:\n",
        "                    weighting_window = top_left\n",
        "                    # print('top left')\n",
        "                elif y == image_width - window_size:\n",
        "                    # print('top right')\n",
        "                    weighting_window = top_right\n",
        "                else:\n",
        "                    weighting_window = top\n",
        "                    # print('top ')\n",
        "            elif x == image_height - window_size:\n",
        "                if y == 0:\n",
        "                    weighting_window = bottom_left\n",
        "                    # print('bottom left')\n",
        "                elif y == image_width - window_size:\n",
        "                    weighting_window = bottom_right\n",
        "                    # print('bottom right')\n",
        "                else:\n",
        "                    weighting_window = bottom\n",
        "                    # print('bottom')\n",
        "            elif y == 0:\n",
        "                weighting_window = left\n",
        "                # print('left')\n",
        "            elif y == image_width - window_size:\n",
        "                weighting_window = right\n",
        "                # print('right')\n",
        "            else:\n",
        "                weighting_window = middle\n",
        "                # print('middle')\n",
        "            square_section = mirrored_image[x:x + window_size, y:y + window_size]\n",
        "            weights[x:x + window_size, y:y + window_size] += weighting_window\n",
        "            # tryout[x:x + window_size, y:y + window_size] += np.ones((window_size, window_size))*weighting_window\n",
        "            # square_section = preprocess_image(square_section) # TODO: prehodit tohle, at se to dela jednou pro celej obrazek, ne pro patche?\n",
        "            square_tensor = test_transform(square_section).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
        "\n",
        "            # Forward pass through the model\n",
        "            with torch.no_grad():\n",
        "                output = torch.sigmoid(model(square_tensor)).float()\n",
        "\n",
        "            # Scale the probablity to 0-255\n",
        "            output = output*255\n",
        "            # output = output.to(torch.uint8)\n",
        "            output_pil = output.squeeze(0).cpu().numpy().squeeze()\n",
        "            # cv2_imshow(output_pil)\n",
        "            output_probs[x:x+window_size, y:y+window_size] += output_pil*weighting_window\n",
        "    # Crop\n",
        "    # cv.imwrite(os.path.join(output_folder, \"probs\"+\".png\"), output_probs)\n",
        "\n",
        "    output_probs = output_probs[oh:original_height+oh, ow:original_width+ow]\n",
        "    weights *= 255\n",
        "    # weights = weights[:original_height, :original_width]*255\n",
        "    # tryout = tryout[:original_height, :original_width]*255\n",
        "\n",
        "    # Apply weights\n",
        "    # output_probs /= weights\n",
        "\n",
        "    # Create image from mask\n",
        "    output_mask = np.where(output_probs > 127, 255, 0)\n",
        "    output_mask = output_mask.astype(np.uint8)\n",
        "    filename_ext = os.path.basename(image_path)\n",
        "    filename, ext = os.path.splitext(filename_ext)\n",
        "    # cv.imwrite(os.path.join(output_folder, filename+\"_mirrored\"+ext), mirrored_image)\n",
        "\n",
        "    # Merge image with created mask\n",
        "    out_mask_path = os.path.join(output_folder, filename+\"_new_mask\"+ext)\n",
        "    merge = merge_images(input_image, output_mask)\n",
        "    cv.imwrite(os.path.join(output_folder, filename+\"_new_mask_merge\"+ext), merge)\n",
        "\n",
        "    # cv.imwrite(os.path.join(output_folder, filename+\"_probs\"+ext), output_probs)\n",
        "    cv.imwrite(out_mask_path, output_mask)\n",
        "    # cv.imwrite(os.path.join(output_folder, filename+\"_weights\"+ext), weights)\n",
        "    return out_mask_path\n",
        "\n",
        "# def inference_on_image_with_overlap(model, image_path, output_folder):\n",
        "#     window_size = 512\n",
        "#     oh, ow = 124, 124\n",
        "#     input_image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "#     image_height, image_width = input_image.shape\n",
        "#     original_height, original_width = image_height, image_width\n",
        "#     bottom_edge = image_height % (window_size - oh)\n",
        "#     right_edge = image_width % (window_size - ow)\n",
        "#     mirrored_image = np.zeros((image_height+bottom_edge, image_width+right_edge)).astype(np.uint8)\n",
        "#     mirrored_image[:image_height, :image_width] = input_image\n",
        "#     mirrored_image[image_height:, :image_width] = np.flipud(input_image[image_height-bottom_edge:, :])\n",
        "#     mirrored_image[:, image_width:] = np.fliplr(mirrored_image[:, image_width-right_edge:image_width])\n",
        "#     image_height += bottom_edge\n",
        "#     image_width += right_edge\n",
        "#     weights = np.zeros((image_height, image_width))\n",
        "#     # tryout = np.zeros((image_height, image_width))\n",
        "#     output_probs = np.zeros((image_height, image_width))\n",
        "#     output_mask = np.zeros((image_height, image_width))\n",
        "#     middle, top_left, top, top_right, right, bottom_right, bottom, bottom_left, left = create_weighting_patches(window_size, oh)\n",
        "\n",
        "#     for x in range(0, image_height-window_size+1, window_size - oh):\n",
        "#         for y in range(0, image_width-window_size+1, window_size - ow):\n",
        "#             # Choose weighting window\n",
        "#             if x == 0:\n",
        "#                 if y == 0:\n",
        "#                     if original_height != window_size:\n",
        "#                         weighting_window = top_left\n",
        "#                     else:\n",
        "#                         weighting_window = np.ones((window_size, window_size))\n",
        "#                 elif y == window_size - ow - 1:\n",
        "#                     weighting_window = top_right\n",
        "#                 else:\n",
        "#                     weighting_window = top\n",
        "#             elif x == window_size - oh - 1:\n",
        "#                 if y == 0:\n",
        "#                     weighting_window = bottom_left\n",
        "#                 elif y == window_size - ow - 1:\n",
        "#                     weighting_window = bottom_right\n",
        "#                 else:\n",
        "#                     weighting_window = bottom\n",
        "#             elif y == 0:\n",
        "#                 weighting_window = left\n",
        "#             elif y == window_size - ow - 1:\n",
        "#                 weighting_window = right\n",
        "#             else:\n",
        "#                 weighting_window = middle\n",
        "#             square_section = mirrored_image[x:x + window_size, y:y + window_size]\n",
        "#             weights[x:x + window_size, y:y + window_size] = weighting_window\n",
        "#             # tryout[x:x + window_size, y:y + window_size] += np.ones((window_size, window_size))*weighting_window\n",
        "#             square_section = preprocess_image(square_section)\n",
        "#             square_tensor = test_transform(square_section).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
        "\n",
        "#             # Forward pass through the model\n",
        "#             with torch.no_grad():\n",
        "#                 output = torch.sigmoid(model(square_tensor)).float()\n",
        "\n",
        "#             # Scale the probablity to 0-255\n",
        "#             output = output*255\n",
        "#             output = output.to(torch.uint8)\n",
        "#             output_pil = output.squeeze(0).cpu().numpy()\n",
        "#             output_probs[x:x+window_size, y:y+window_size] += output_pil.squeeze()*weighting_window\n",
        "#     # Crop\n",
        "#     output_probs = output_probs[:original_height, :original_width]\n",
        "#     # weights = weights[:original_height, :original_width]*255\n",
        "#     # tryout = tryout[:original_height, :original_width]*255\n",
        "\n",
        "#     # Apply weights\n",
        "#     # output_probs /= weights\n",
        "\n",
        "#     # Create image from mask\n",
        "#     output_mask = np.where(output_probs > 127, 255, 0)\n",
        "#     output_mask = output_mask.astype(np.uint8)\n",
        "#     filename_ext = os.path.basename(image_path)\n",
        "#     filename, ext = os.path.splitext(filename_ext)\n",
        "\n",
        "#     # Merge image with created mask\n",
        "#     out_mask_path = os.path.join(output_folder, filename+\"_mask\"+ext)\n",
        "#     merge = merge_images(input_image, output_mask)\n",
        "#     cv.imwrite(os.path.join(output_folder, filename+\"_merge\"+ext), merge)\n",
        "\n",
        "#     cv.imwrite(os.path.join(output_folder, filename+\"_probs\"+ext), output_probs)\n",
        "#     cv.imwrite(out_mask_path, output_mask)\n",
        "#     # cv.imwrite(os.path.join(output_folder, filename+\"_weights\"+ext), weights)\n",
        "#     return out_mask_path\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "    image = nlm_filt(image)\n",
        "    # image = wavelet_denoise(image, threshold=1.5)\n",
        "    # image = apply_clahe(image)\n",
        "    # image = cv.medianBlur(image, 7)\n",
        "    return image\n",
        "\n",
        "\n",
        "def apply_clahe(image):\n",
        "    clahe = cv.createCLAHE(clipLimit=0.8, tileGridSize=(8, 8))\n",
        "    clahe_image = clahe.apply(image)\n",
        "    return clahe_image\n",
        "\n",
        "\n",
        "def create_image_patches(image_folder, mask_folder, output_folder, patch_size):\n",
        "    image_patches_path = os.path.join(output_folder,'image_patches')\n",
        "    mask_patches_path = os.path.join(output_folder,'mask_patches')\n",
        "    # rejected_path = os.path.join(output_folder,'rejected')\n",
        "    # print(image_path)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    if os.path.exists(image_patches_path):\n",
        "        shutil.rmtree(image_patches_path)\n",
        "    os.mkdir(image_patches_path)\n",
        "    if os.path.exists(mask_patches_path):\n",
        "        shutil.rmtree(mask_patches_path)\n",
        "    os.mkdir(mask_patches_path)\n",
        "    # if os.path.exists(rejected_path):\n",
        "    #     shutil.rmtree(rejected_path)\n",
        "    # os.mkdir(rejected_path)\n",
        "\n",
        "    patch_area = patch_size**2\n",
        "    fenestration_area_thresh = 0.0 #0.01\n",
        "    image_filenames = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
        "    image_filenames = sorted(image_filenames)\n",
        "    mask_filenames = [f for f in os.listdir(mask_folder) if os.path.isfile(os.path.join(mask_folder, f))]\n",
        "    mask_filenames = sorted(mask_filenames)\n",
        "\n",
        "    for image_name, mask_name in zip(image_filenames, mask_filenames):\n",
        "        # if image_name.endswith(\".tif\"): # TODO: tohle mozna odstranit\n",
        "        input_path = os.path.join(image_folder, image_name)\n",
        "        mask_path = os.path.join(mask_folder, mask_name)\n",
        "\n",
        "        img = cv.imread(input_path, cv.IMREAD_GRAYSCALE)\n",
        "        mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
        "        height, width = img.shape\n",
        "\n",
        "        shape = (height // patch_size, width // patch_size, patch_size, patch_size)\n",
        "        strides = (patch_size * width , patch_size , width, 1)\n",
        "        # strides = (patch_size * width , patch_size)\n",
        "\n",
        "        # img_strided = as_strided(img, shape=(width//patch_size, height//patch_size, patch_size, patch_size),\n",
        "        #              strides=img.strides + img.strides, writeable=False)\n",
        "        img_strided = as_strided(img, shape=shape,\n",
        "                        strides=strides, writeable=False) #TODO: check if the patches do not overlap\n",
        "        mask_strided = as_strided(mask, shape=shape,\n",
        "                        strides=strides, writeable=False)\n",
        "\n",
        "        for i in range(img_strided.shape[0]):\n",
        "            for j in range(img_strided.shape[1]):\n",
        "                img_patch = img_strided[i, j]\n",
        "                mask_patch = mask_strided[i, j]\n",
        "                # Compute the percentage of white pixels\n",
        "                fenestration_area = np.sum(mask_patch == 255)\n",
        "                # print(fenestration_area)\n",
        "                # fenestration_percentage = fenestration_area/patch_area\n",
        "                if fenestration_area >= fenestration_area_thresh:\n",
        "                    patch_filename = f\"{os.path.splitext(os.path.basename(image_name))[0]}_patch_{i}_{j}.tif\"\n",
        "                    # preprocess image\n",
        "                    img_patch = preprocess_image(img_patch)\n",
        "                    cv.imwrite(os.path.join(image_patches_path, patch_filename), img_patch)\n",
        "                    cv.imwrite(os.path.join(mask_patches_path, patch_filename), mask_patch)\n",
        "                    # print(\"written patch \", patch_filename)\n",
        "                else:\n",
        "                    print(\"not writing patch\")\n",
        "    return image_patches_path, mask_patches_path\n",
        "\n",
        "\n",
        "# Denoising\n",
        "#   References for non-local means filtering and noise variance estimation:\n",
        "#\n",
        "#   [1] Antoni Buades, Bartomeu Coll, and Jean-Michel Morel, A Non-Local\n",
        "#       Algorithm for Image Denoising, Computer Vision and Pattern\n",
        "#       Recognition 2005. CVPR 2005, Volume 2, (2005), pp. 60-65.\n",
        "#   [2] John Immerkaer, Fast Noise Variance Estimation, Computer Vision and\n",
        "#       Image Understanding, Volume 64, Issue 2, (1996), pp. 300-302\n",
        "\n",
        "def estimate_degree_of_smoothing(I): # This is how the estimation is done in Matlab (see imnlmfilt in Matlab)\n",
        "    H, W = I.shape\n",
        "    I = I.astype(np.float32)\n",
        "    kernel = np.array([[1, -2, 1], [-2, 4, -2], [1, -2, 1]])\n",
        "    conv_result = np.abs(convolve2d(I[:, :], kernel, mode='valid'))\n",
        "    res = np.sum(conv_result)\n",
        "    degree_of_smoothing = (res * np.sqrt(0.5 * np.pi) / (6 * (W - 2) * (H - 2)))\n",
        "    if degree_of_smoothing == 0:\n",
        "        degree_of_smoothing = np.finfo(np.float32).eps\n",
        "    return degree_of_smoothing\n",
        "\n",
        "\n",
        "def nlm_filt(image):\n",
        "    window_size = 5\n",
        "    search_window_size = 21\n",
        "    degree_of_smoothing = estimate_degree_of_smoothing(image)\n",
        "    image = cv.fastNlMeansDenoising(image, None, h = degree_of_smoothing, templateWindowSize = 5, searchWindowSize = 21)\n",
        "    return image\n",
        "\n",
        "\n",
        "def anscombe_transform(data):\n",
        "    return 2.0 * np.sqrt(data + 3.0/8.0)\n",
        "\n",
        "\n",
        "def inverse_anscombe_transform(data):\n",
        "    # Reference\n",
        "    # https://github.com/broxtronix/pymultiscale/blob/master/pymultiscale/anscombe.py\n",
        "    return (1.0/4.0 * np.power(data, 2) +\n",
        "        1.0/4.0 * np.sqrt(3.0/2.0) * np.power(data, -1.0) -\n",
        "        11.0/8.0 * np.power(data, -2.0) +\n",
        "        5.0/8.0 * np.sqrt(3.0/2.0) * np.power(data, -3.0) - 1.0 / 8.0)\n",
        "\n",
        "\n",
        "def wavelet_denoising(data, threshold=1.5, wavelet='coif4', threshold_type='soft'):\n",
        "    coeffs = pywt.wavedec2(data, wavelet = wavelet, level=3)\n",
        "    coeffs[-1] = tuple(pywt.threshold(c, threshold, threshold_type) for c in coeffs[-1])\n",
        "    coeffs[-2] = tuple(pywt.threshold(c, threshold, threshold_type) for c in coeffs[-2])\n",
        "    coeffs[-3] = tuple(pywt.threshold(c, threshold, threshold_type) for c in coeffs[-3])\n",
        "    return pywt.waverec2(coeffs, wavelet)\n",
        "\n",
        "\n",
        "def wavelet_denoise(image, threshold):\n",
        "    image = anscombe_transform(image)\n",
        "    image = wavelet_denoising(image, threshold)\n",
        "    image = inverse_anscombe_transform(image)\n",
        "    # TODO: not sure this is the correct way how to do this\n",
        "    image = image/np.max(image)*255\n",
        "    return image.astype(np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLHlKdZ_MnGj"
      },
      "source": [
        "## Training utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dvOsCa6iiNrd"
      },
      "outputs": [],
      "source": [
        "# This is the official implementation of BoundaryDOULoss https://arxiv.org/pdf/2308.00220.pdf\n",
        "# Taken from: https://github.com/sunfan-bvb/BoundaryDoULoss/tree/main\n",
        "class BoundaryDoULoss(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(BoundaryDoULoss, self).__init__()\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def _one_hot_encoder(self, input_tensor):\n",
        "        tensor_list = []\n",
        "        for i in range(self.n_classes):\n",
        "            temp_prob = input_tensor == i\n",
        "            tensor_list.append(temp_prob.unsqueeze(1))\n",
        "        output_tensor = torch.cat(tensor_list, dim=1)\n",
        "        return output_tensor.float()\n",
        "\n",
        "    def _adaptive_size(self, score, target):\n",
        "        kernel = torch.Tensor([[0,1,0], [1,1,1], [0,1,0]])\n",
        "        padding_out = torch.zeros((target.shape[0], target.shape[-2]+2, target.shape[-1]+2))\n",
        "        padding_out[:, 1:-1, 1:-1] = target\n",
        "        h, w = 3, 3\n",
        "\n",
        "        Y = torch.zeros((padding_out.shape[0], padding_out.shape[1] - h + 1, padding_out.shape[2] - w + 1)).cuda()\n",
        "        for i in range(Y.shape[0]):\n",
        "            Y[i, :, :] = torch.conv2d(target[i].unsqueeze(0).unsqueeze(0), kernel.unsqueeze(0).unsqueeze(0).cuda(), padding=1)\n",
        "        Y = Y * target\n",
        "        Y[Y == 5] = 0\n",
        "        C = torch.count_nonzero(Y)\n",
        "        S = torch.count_nonzero(target)\n",
        "        smooth = 1e-5\n",
        "        alpha = 1 - (C + smooth) / (S + smooth)\n",
        "        alpha = 2 * alpha - 1\n",
        "\n",
        "        intersect = torch.sum(score * target)\n",
        "        y_sum = torch.sum(target * target)\n",
        "        z_sum = torch.sum(score * score)\n",
        "        alpha = min(alpha, 0.8)  ## We recommend using a truncated alpha of 0.8, as using truncation gives better results on some datasets and has rarely effect on others.\n",
        "        loss = (z_sum + y_sum - 2 * intersect + smooth) / (z_sum + y_sum - (1 + alpha) * intersect + smooth)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def forward(self, inputs, target):\n",
        "        inputs = torch.softmax(inputs, dim=1)\n",
        "        target = self._one_hot_encoder(target)\n",
        "        target = target.squeeze(1)\n",
        "\n",
        "        assert inputs.size() == target.size(), 'predict {} & target {} shape do not match'.format(inputs.size(), target.size())\n",
        "\n",
        "        loss = 0.0\n",
        "        for i in range(0, self.n_classes):\n",
        "            loss += self._adaptive_size(inputs[:, 0], target[:, 0])#(inputs[:, i], target[:, i])\n",
        "        return loss / self.n_classes\n",
        "\n",
        "\n",
        "def save_checkpoint(model, model_path):#, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    model.save(model_path)\n",
        "    # torch.save(state, filename)\n",
        "\n",
        "def save_state_dict(model, model_path):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "def load_state_dict(model, model_path):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "def validate_model(model, loader, loss_fn):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for idx, (x, y) in enumerate(loader):\n",
        "            x = x.to(DEVICE)\n",
        "            y = y.to(DEVICE).unsqueeze(1)\n",
        "            # Forward\n",
        "            preds = model(x)\n",
        "            # loss_fn = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(16))\n",
        "            # loss = loss_fn(preds, y)\n",
        "            loss = get_loss(preds, y, loss_fn)\n",
        "            running_loss += loss.cpu()\n",
        "            preds = (preds > 0.5).float()\n",
        "\n",
        "            # num_correct += (preds == y).sum()\n",
        "            # num_pixels += torch.numel(preds)\n",
        "            dice_score += (2*(preds*y).sum()) / (preds+y).sum() + 1e-8 # this is a better predictor\n",
        "    # print(\n",
        "    #     f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f} ()\"\n",
        "    # )\n",
        "    dice_score = dice_score/(idx+1)\n",
        "    val_loss = running_loss/(idx+1)\n",
        "    # dice_score = dice_score/len(loader)\n",
        "    # val_loss = running_loss/len(loader) #TODO: not sure this is correct(dividing by batch size?)\n",
        "    # print(f\"Dice score is {dice_score}\")\n",
        "    # val_losses.append(running_loss/len(loader))\n",
        "    # dice_scores.append(dice_score.cpu())\n",
        "    model.train()\n",
        "    return val_loss, dice_score.cpu()\n",
        "\n",
        "\n",
        "\n",
        "# def save_predictions_as_imgs(\n",
        "#         loader, model, folder=\"saved_images\", device=\"cpu\"\n",
        "# ):\n",
        "#     model.eval()\n",
        "#     for idx, (x, y) in enumerate(loader):\n",
        "#         x = x.to(device=device)\n",
        "#         with torch.no_grad():\n",
        "#             preds = torch.sigmoid(model(x))\n",
        "#             preds = (preds > 0.5).float()\n",
        "#         # print(f\"preds max{preds.max()}\")\n",
        "#         # print(f\"y max {y.max()}\")\n",
        "#         # torchvision.utils.save_image(preds, os.path.join(folder, f\"pred{idx}.png\"))\n",
        "#         # torchvision.utils.save_image(y.unsqueeze(1), os.path.join(folder, f\"pred{idx}_correct.png\"))\n",
        "#             imshow(preds)\n",
        "#             imshow(y.unsqueeze(1))\n",
        "#         break # TODO: change this so it does not loop\n",
        "#     model.train()\n",
        "#     print(\"Saving prediction as images.\")\n",
        "\n",
        "def view_prediction(loader, model, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        x = x.to(device=device)\n",
        "        with torch.no_grad():\n",
        "            # output = torch.softmax(model(x), dim=1)\n",
        "            output = torch.sigmoid(model(x))\n",
        "            preds = (output > 0.5).float()\n",
        "            preds = preds.cpu().data.numpy()\n",
        "            output = output.cpu().data.numpy()\n",
        "            for i in range(preds.shape[0]):\n",
        "                f=plt.figure(figsize=(128,32))\n",
        "                # Original image\n",
        "                plt.subplot(1,5*preds.shape[0],i+1)\n",
        "                x = x.cpu()\n",
        "                plt.imshow(x[i, 0, :, :], cmap='gray') # preds is a batch\n",
        "                plt.title('Validation image')\n",
        "                # NN output(probability)\n",
        "                plt.subplot(1,5*preds.shape[0],i+2)\n",
        "                plt.imshow(output[i, 0, :, :], interpolation='nearest', cmap='magma') # preds is a batch\n",
        "                plt.title('NN output')\n",
        "                # Segmentation\n",
        "                plt.subplot(1,5*preds.shape[0],i+3)\n",
        "                plt.imshow(preds[i, 0, :, :], cmap='gray') # preds is a batch\n",
        "                plt.title('Prediction')\n",
        "                # True mask\n",
        "                plt.subplot(1,5*preds.shape[0],i+4)\n",
        "                plt.imshow(y.unsqueeze(1)[i, 0, :, :], cmap='gray')\n",
        "                plt.title('Ground truth')\n",
        "                # IoU\n",
        "                plt.subplot(1,5*preds.shape[0],i+5)\n",
        "                im1 = y.unsqueeze(1)[i, 0, :, :]\n",
        "                im2 = preds[i, 0, :, :]\n",
        "                plt.imshow(im1, alpha=0.8, cmap='Blues')\n",
        "                plt.imshow(im2, alpha=0.6,cmap='Oranges')\n",
        "                plt.title('IoU')\n",
        "\n",
        "            plt.show()\n",
        "            break # TODO: change this so it does not loop\n",
        "    model.train()\n",
        "\n",
        "\n",
        "# def getClassWeights(mask_path, train_indices):\n",
        "#     mask_dir_list = sorted(os.listdir(mask_path))\n",
        "#     class_count = np.zeros(2, dtype=int)\n",
        "#     for i in train_indices:\n",
        "#         mask = cv.imread(os.path.join(mask_path, mask_dir_list[i]), cv.IMREAD_GRAYSCALE) #np.array(Image.open(os.path.join(mask_path, mask_dir_list[i])).convert('L'), dtype=np.float32)\n",
        "#         mask[mask == 255.0] = 1\n",
        "#         class_count[0] += mask.shape[0]*mask.shape[1] - mask.sum()\n",
        "#         class_count[1] += mask.sum()\n",
        "\n",
        "#     n_samples = class_count.sum()\n",
        "#     n_classes = 2\n",
        "\n",
        "#     class_weights = n_samples / (n_classes * class_count)\n",
        "#     return torch.from_numpy(class_weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debug"
      ],
      "metadata": {
        "id": "FUoJD88eOFO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.ticker import PercentFormatter\n",
        "\n",
        "def show_fitted_ellipses(image_path, ellipses):\n",
        "    image = cv.imread(image_path)\n",
        "    for ellipse in ellipses:\n",
        "        if ellipse is not None:\n",
        "            cv.ellipse(image, ellipse, (0, 0, 255), 1)\n",
        "            center, axes, angle = ellipse\n",
        "            center_x, center_y = center\n",
        "            major_axis_length, minor_axis_length = axes\n",
        "            rotation_angle = angle\n",
        "            # print(center_x, center_y)\n",
        "            cv.circle(image, (int(center_x), int(center_y)),radius=1, color=(0, 0, 255), thickness=-1)\n",
        "\n",
        "        # print(\"Center:\", center)\n",
        "        # print(\"Major Axis Length:\", major_axis_length)\n",
        "        # print(\"Minor Axis Length:\", minor_axis_length)\n",
        "        # print(\"Rotation Angle:\", rotation_angle)\n",
        "\n",
        "    cv2_imshow(image)\n",
        "\n",
        "def fit_ellipses(filtered_contours, centers):\n",
        "    ellipses = []\n",
        "    for contour, cnt_center in zip(filtered_contours, centers):\n",
        "        if len(contour) >= 5:  # Ellipse fitting requires at least 5 points\n",
        "            ellipse = cv.fitEllipse(contour) # TODO: maybe try a different computation, if this does not work well on edges (probably ok)\n",
        "            # ellipse = cv.minAreaRect(cnt) # the fitEllipse functions fails sometimes(when the fenestration is on the edge and only a part of it is visible)\n",
        "            dist = cv.norm(cnt_center, ellipse[0])\n",
        "            # print(dist)\n",
        "            if dist < 20:\n",
        "                ellipses.append(ellipse)\n",
        "            else:\n",
        "                ellipses.append(None)\n",
        "        else:\n",
        "            ellipses.append(None)\n",
        "    return ellipses\n",
        "\n",
        "def find_fenestration_contours(image_path):\n",
        "    seg_mask = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
        "    contours, _ = cv.findContours(seg_mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "    return contours\n",
        "    # image = cv.cvtColor(seg_mask, cv.COLOR_GRAY2RGB)\n",
        "    # image_el = image.copy()\n",
        "    # cv.drawContours(image, contours, -1, (0, 0, 255), 1)\n",
        "    # cv2_imshow(image)\n",
        "\n",
        "    # Remove noise and small artifacts\n",
        "    # min_contour_area = 10\n",
        "    # filtered_contours = [cnt for cnt in contours if cv.contourArea(cnt) > min_contour_area]\n",
        "    # return filtered_contours\n",
        "\n",
        "def find_contour_centers(contours):\n",
        "    contour_centers = []\n",
        "    for cnt in contours:\n",
        "        M = cv.moments(cnt)\n",
        "        center_x = int(M['m10'] / (M['m00'] + 1e-10))\n",
        "        center_y = int(M['m01'] / (M['m00'] + 1e-10))\n",
        "        contour_centers.append((center_x, center_y))\n",
        "    # print(contour_centers)\n",
        "    return contour_centers\n",
        "\n",
        "def equivalent_circle_diameter(major_axis_length, minor_axis_length):\n",
        "    return math.sqrt(major_axis_length * minor_axis_length)\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "\n",
        "\n",
        "\n",
        "def show_statistics(fenestration_areas, fenestration_areas_from_ellipses, roundness_of_ellipses, equivalent_diameters, min_roundness=0, min_d=None, max_d=None):\n",
        "    palette = itertools.cycle(sns.color_palette())\n",
        "    plt.figure(figsize=(21, 5))\n",
        "\n",
        "    # Plot histogram of fenestration areas\n",
        "    plt.subplot(1, 4, 1)\n",
        "    sns.histplot(fenestration_areas, stat='probability')\n",
        "    # plt.hist(fenestration_areas, bins=20, color='red', edgecolor='black', density=density)\n",
        "    plt.title('Histogram of Fenestration Areas')\n",
        "    plt.xlabel('Area ($\\mathrm{nm}^2$)')\n",
        "    # plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot histogram of areas of fitted elipses\n",
        "    plt.subplot(1, 4, 2)\n",
        "    sns.histplot(fenestration_areas_from_ellipses, stat='probability', color=next(palette)) # this will be the first color (blue)\n",
        "    # plt.hist(fenestration_areas_from_ellipses, bins=20, color='red', edgecolor='black', density=density)\n",
        "    plt.title('Histogram of Fenestration Areas (fitted ellipses)')\n",
        "    plt.xlabel('Area ($\\mathrm{nm}^2$)')\n",
        "    # plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot histogram of roundness\n",
        "    plt.subplot(1, 4, 3)\n",
        "    r = sns.histplot(roundness_of_ellipses, stat='probability', color=next(palette), binwidth=0.025)\n",
        "    r.set(xlim=(min_roundness, None))\n",
        "    # plt.hist(roundness_of_ellipses, bins=10, color='blue', edgecolor='black', density=density)\n",
        "    plt.title('Histogram of Roundness')\n",
        "    plt.xlabel('Roundness (-)')\n",
        "    # plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "    # print(np.array(roundness_of_ellipses).max())\n",
        "\n",
        "    # Plot histogram of equivalent circle diameters\n",
        "    plt.subplot(1, 4, 4)\n",
        "    d = sns.histplot(equivalent_diameters, stat='probability', color=next(palette), binwidth=10)\n",
        "    d.set(xlim=(0, max_d))\n",
        "    # plt.hist(equivalent_diameters, bins=20, color='green', edgecolor='black', density=density)\n",
        "    plt.title('Histogram of Equivalent Circle Diameters')\n",
        "    plt.xlabel('Diameter (nm)')\n",
        "    # plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "\n",
        "\n",
        "    # plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
        "\n",
        "\n",
        "\n",
        "# Mask statistics debug\n",
        "# One pixel corresponds to 10.62 nm\n",
        "image_path = \"./gdrive/MyDrive/ROIs_manually_corrected/augment_mask/_0_379.tif\"\n",
        "image_path = \"./gdrive/MyDrive/lsec_test/old11_CA150_NE_01_original_mask.tif\" # Image from semiautomatic labeling\n",
        "\n",
        "\n",
        "pixel_size_nm = 10.62\n",
        "contours = find_fenestration_contours(image_path)\n",
        "fenestration_areas = [cv.contourArea(cnt) * (pixel_size_nm**2) for cnt in contours]\n",
        "contour_centers = find_contour_centers(contours)\n",
        "ellipses = fit_ellipses(contours, contour_centers)\n",
        "\n",
        "# Show image of fitted ellipses\n",
        "# show_fitted_ellipses(image_path, ellipses)\n",
        "\n",
        "roundness_of_ellipses = []\n",
        "equivalent_diameters = []\n",
        "fenestration_areas_from_ellipses = []\n",
        "\n",
        "for ellipse in ellipses:\n",
        "    center, axes, angle = ellipse\n",
        "    # center_x, center_y = center\n",
        "    major_axis_length, minor_axis_length = axes\n",
        "    roundness = minor_axis_length/major_axis_length\n",
        "    roundness_of_ellipses.append(roundness)\n",
        "    # rotation_angle = angle\n",
        "    diameter = pixel_size_nm * equivalent_circle_diameter(major_axis_length, minor_axis_length)\n",
        "    equivalent_diameters.append(diameter)\n",
        "    fenestration_areas_from_ellipses.append((diameter**2)/4*math.pi)\n",
        "\n",
        "# show_statistics(fenestration_areas, fenestration_areas_from_ellipses, roundness_of_ellipses, equivalent_diameters)\n",
        "\n",
        "\n",
        "# Display the number of circles and their fitted ellipses\n",
        "print(\"Number of fenestrations:\", len(contours))\n",
        "print(\"Number of fitted ellipses:\", len(ellipses))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtPrBpQBcsmn",
        "outputId": "a5dd0958-3619-441a-b879-5377ccfeefe9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of fenestrations: 0\n",
            "Number of fitted ellipses: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Wavelet filtering debug\n",
        "\n",
        "# image_folder = \"./gdrive/MyDrive/ROIs_manually_corrected/train_images\"\n",
        "# images = os.listdir(image_folder)\n",
        "# image_name = images[0]\n",
        "# image = cv.imread(os.path.join(image_folder, image_name), cv.IMREAD_GRAYSCALE)\n",
        "# # cv2_imshow(image)\n",
        "\n",
        "# denoised_image = wavelet_denoise(image)\n",
        "# # cv2_imshow(denoised_image)\n",
        "\n"
      ],
      "metadata": {
        "id": "P9hdx_pYOOjw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w8Va0EXGIlq"
      },
      "source": [
        "# U-Net definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mSqH1xk-iNpJ"
      },
      "outputs": [],
      "source": [
        "# import torchvision.transforms.functional as TF\n",
        "\n",
        "\n",
        "def double_conv(in_ch, out_ch, activation):\n",
        "    if activation == 'ReLU':\n",
        "        conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=out_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    elif activation == 'GeLU':\n",
        "        conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.GeLU(approximate='none'),\n",
        "            nn.Conv2d(in_channels=out_ch,out_channels=out_ch,kernel_size=3,stride=1,padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.GeLU(approximate='none')\n",
        "        )\n",
        "    return conv\n",
        "\n",
        "\n",
        "def padder(left_tensor, right_tensor, device: str):\n",
        "  # left_tensor is the tensor on the encoder side of UNET\n",
        "  # right_tensor is the tensor on the decoder side  of the UNET\n",
        "\n",
        "    if left_tensor.shape != right_tensor.shape:\n",
        "        padded = torch.zeros(left_tensor.shape)\n",
        "        padded[:, :, :right_tensor.shape[2], :right_tensor.shape[3]] = right_tensor\n",
        "        return padded.to(device)\n",
        "\n",
        "    return right_tensor.to(device)\n",
        "\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, device, dropout_probability, activations, out_activation):\n",
        "        super(UNET, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.device = device\n",
        "        self.dropout = nn.Dropout(p=dropout_probability)\n",
        "        self.activations = activations\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "        self.down_conv_1 = double_conv(in_ch=self.in_channels,out_ch=64, activation=activations)\n",
        "        self.down_conv_2 = double_conv(in_ch=64,out_ch=128, activation=activations)\n",
        "        self.down_conv_3 = double_conv(in_ch=128,out_ch=256, activation=activations)\n",
        "        self.down_conv_4 = double_conv(in_ch=256,out_ch=512, activation=activations)\n",
        "        self.down_conv_5 = double_conv(in_ch=512,out_ch=1024, activation=activations)\n",
        "        #print(self.down_conv_1)\n",
        "\n",
        "        self.up_conv_trans_1 = nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=2,stride=2)\n",
        "        self.up_conv_trans_2 = nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=2,stride=2)\n",
        "        self.up_conv_trans_3 = nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=2,stride=2)\n",
        "        self.up_conv_trans_4 = nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=2,stride=2)\n",
        "\n",
        "        self.up_conv_1 = double_conv(in_ch=1024,out_ch=512, activation=activations)\n",
        "        self.up_conv_2 = double_conv(in_ch=512,out_ch=256, activation=activations)\n",
        "        self.up_conv_3 = double_conv(in_ch=256,out_ch=128, activation=activations)\n",
        "        self.up_conv_4 = double_conv(in_ch=128,out_ch=64, activation=activations)\n",
        "\n",
        "        self.conv_1x1 = nn.Conv2d(in_channels=64,out_channels=self.out_channels,kernel_size=1,stride=1)\n",
        "        self.out_activation = out_activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = x.to(self.device)\n",
        "        x1 = self.down_conv_1(x)\n",
        "        p1 = self.max_pool(x1)\n",
        "        x2 = self.down_conv_2(p1)\n",
        "        p2 = self.max_pool(x2)\n",
        "        p2 = self.dropout(p2)\n",
        "        x3 = self.down_conv_3(p2)\n",
        "        p3 = self.max_pool(x3)\n",
        "        p3 = self.dropout(p3)\n",
        "        x4 = self.down_conv_4(p3)\n",
        "        p4 = self.max_pool(x4)\n",
        "        p4 = self.dropout(p4)\n",
        "        x5 = self.down_conv_5(p4)\n",
        "\n",
        "        # decoding\n",
        "        d1 = self.up_conv_trans_1(x5)  # up transpose convolution (\"up sampling\" as called in UNET paper)\n",
        "        pad1 = padder(x4,d1, self.device) # padding d1 to match x4 shape\n",
        "        cat1 = torch.cat([x4,pad1],dim=1) # concatenating padded d1 and x4 on channel dimension(dim 1) [batch(dim 0),channel(dim 1),height(dim 2),width(dim 3)]\n",
        "        cat1 = self.dropout(cat1)\n",
        "        uc1 = self.up_conv_1(cat1) # 1st up double convolution\n",
        "\n",
        "        d2 = self.up_conv_trans_2(uc1)\n",
        "        pad2 = padder(x3,d2, self.device)\n",
        "        cat2 = torch.cat([x3,pad2],dim=1)\n",
        "        cat2 = self.dropout(cat2)\n",
        "        uc2 = self.up_conv_2(cat2)\n",
        "\n",
        "        d3 = self.up_conv_trans_3(uc2)\n",
        "        pad3 = padder(x2,d3, self.device)\n",
        "        cat3 = torch.cat([x2,pad3],dim=1)\n",
        "        uc3 = self.up_conv_3(cat3)\n",
        "\n",
        "        d4 = self.up_conv_trans_4(uc3)\n",
        "        pad4 = padder(x1,d4, self.device)\n",
        "        cat4 = torch.cat([x1,pad4],dim=1)\n",
        "        uc4 = self.up_conv_4(cat4)\n",
        "\n",
        "        conv_1x1 = self.conv_1x1(uc4)\n",
        "        if self.out_activation == 'sigmoid':\n",
        "            conv_1x1 = torch.sigmoid(conv_1x1)\n",
        "        return conv_1x1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Training patches**"
      ],
      "metadata": {
        "id": "4YW6LWTd45uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "#@markdown ##**Insert Google Drive paths:**\n",
        "\n",
        "#@markdown All Google Drive paths should start with ./gdrive/MyDrive/ (Check the folder structure in the left sidebar under **Files**).\n",
        "\n",
        "#@markdown If you want to create new 512x512 patches, check the following box. If you already have image patches, insert the folders below.\n",
        "create_patches = False # @param {type:\"boolean\"}\n",
        "\n",
        "training_images = './gdrive/MyDrive/lsecs/cropped_selections/images' #@param {type:\"string\"}\n",
        "training_masks = './gdrive/MyDrive/lsecs/cropped_selections/masks' #@param {type:\"string\"}\n",
        "\n",
        "training_images = training_images.strip()\n",
        "training_masks = training_masks.strip()\n",
        "\n",
        "if not os.path.exists(training_images):\n",
        "    print(f'{training_images} does not exist.')\n",
        "if not os.path.exists(training_masks):\n",
        "    print(f'{training_masks} does not exist.')\n"
      ],
      "metadata": {
        "id": "4qR6zmj4U-pC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE_NEW_PATCHES = False\n",
        "# SAVE_PATCHES_TO_DISK = False\n",
        "# CREATE_NEW_PATCHES = False\n",
        "SAVE_PATCHES_TO_DISK = False\n",
        "# Example usage:\n",
        "\n",
        "# training_images = \"./gdrive/MyDrive/ROIs_manually_corrected/train_images\"\n",
        "# training_masks = \"./gdrive/MyDrive/ROIs_manually_corrected/train_masks\"\n",
        "\n",
        "if create_patches:\n",
        "    patch_size = 512  # Define your patch size here\n",
        "    if SAVE_PATCHES_TO_DISK:\n",
        "        output_folder = \"./gdrive/MyDrive/lsecs/cropped_selections/patches\"\n",
        "        print(f'Saving patches to {output_folder}')\n",
        "    else:\n",
        "        output_folder = os.getcwd()\n",
        "    image_patches_path, mask_patches_path = create_image_patches(training_images, training_masks, output_folder, patch_size)\n",
        "else: # The patches will be read from disk\n",
        "    output_folder = \"./gdrive/MyDrive/lsecs/cropped_selections/patches\"\n",
        "    image_patches_path = os.path.join(output_folder, 'image_patches')\n",
        "    mask_patches_path = os.path.join(output_folder, 'mask_patches')\n",
        "\n",
        "print(f'Training image patches are located in {image_patches_path}')\n",
        "print(f'Training mask patches are located in {mask_patches_path}')"
      ],
      "metadata": {
        "id": "UzznzOTP4s53",
        "outputId": "f7c72fd8-1138-4815-da81-f2679851116e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training image patches are located in ./gdrive/MyDrive/lsecs/cropped_selections/patches/image_patches\n",
            "Training mask patches are located in ./gdrive/MyDrive/lsecs/cropped_selections/patches/mask_patches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wandb sweep"
      ],
      "metadata": {
        "id": "WAJp45Xo8p_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_optimizer(model, config, beta1=None, beta2=None):\n",
        "    if config.optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(model.parameters(),\n",
        "                              lr=config.learning_rate,\n",
        "                              weight_decay=config.weight_decay,\n",
        "                              momentum=config.momentum)\n",
        "    elif config.optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(model.parameters(),\n",
        "                               lr=config.learning_rate,\n",
        "                               betas=(config.beta1, config.beta2),\n",
        "                               weight_decay=config.weight_decay)\n",
        "    return optimizer\n",
        "\n",
        "# TRAIN_LOADER = train_loader\n",
        "# VAL_LOADER = val_loader\n",
        "def build_dataloaders(config): # TODO: check if there is a better way to do this\n",
        "    image_patches_path = os.path.join(config.image_patches_path, 'patches_'+ config.image_denoising_methods)\n",
        "    mask_patches_path = os.path.join(config.mask_patches_path, 'patches_'+ config.image_denoising_methods)\n",
        "    image_patches_path = os.path.join(image_patches_path, 'image_patches')\n",
        "    mask_patches_path = os.path.join(mask_patches_path, 'mask_patches')\n",
        "    train_loader, val_loader, _ = get_loaders(\n",
        "        image_patches_path,\n",
        "        mask_patches_path,\n",
        "        config.data_split,\n",
        "        config.batch_size,\n",
        "        num_workers=0,\n",
        "        pin_memory=False\n",
        "    )\n",
        "    return train_loader, val_loader # this is the simplest way to do it, wandb train cannot take any arguments\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, loss_fn):\n",
        "    # model.train()\n",
        "    running_loss = 0\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.unsqueeze(1).to(device=DEVICE)\n",
        "\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast():\n",
        "            predictions = model(data)\n",
        "            # TODO: change this\n",
        "            # loss = F.nll_loss(torch.sigmoid(predictions), targets)\n",
        "            loss = get_loss(predictions, targets, loss_fn)\n",
        "            # loss = loss_fn(predictions, targets)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad() # Zero the gradients\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "        if WANDB_CONNECTED or WANDB_LOG:\n",
        "            wandb.log({\"batch loss\": loss.item()})\n",
        "\n",
        "    number_of_batches = batch_idx+1\n",
        "    return running_loss/number_of_batches\n",
        "\n",
        "def build_model(model_name, dropout, loss_func):\n",
        "    in_channels = 1\n",
        "    out_channels = 1\n",
        "    if '+' in model_name:\n",
        "        name_parts = model_name.split('+')\n",
        "        encoder = name_parts[-2]\n",
        "        weights = name_parts[-1]\n",
        "    if loss_func != 'bcelog' and loss_func != 'weighted_bce':\n",
        "        out_activation = None\n",
        "    else:\n",
        "        out_activation = 'sigmoid'\n",
        "    if model_name == 'plain_unet':\n",
        "        model = UNET(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                device=DEVICE,\n",
        "                dropout_probability=dropout,\n",
        "                activations='ReLU',\n",
        "                out_activation=out_activation).to(DEVICE)\n",
        "    elif 'Unet++' in model_name:\n",
        "        model = smp.UnetPlusPlus(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights=weights,\n",
        "                in_channels=in_channels,\n",
        "                classes=out_channels,\n",
        "                activation=out_activation,).to(DEVICE)\n",
        "    elif 'Linknet' in model_name:\n",
        "        model = smp.Linknet(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights=weights,\n",
        "                in_channels=in_channels,\n",
        "                classes=out_channels,\n",
        "                activation=out_activation,).to(DEVICE)\n",
        "    elif 'FPN' in model_name:\n",
        "        model = smp.FPN(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights=weights,\n",
        "                in_channels=in_channels,\n",
        "                classes=out_channels,\n",
        "                activation=out_activation,).to(DEVICE)\n",
        "    elif 'DeepLabV3' in model_name:\n",
        "        model = smp.DeepLabV3(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights=weights,\n",
        "                in_channels=in_channels,\n",
        "                classes=out_channels,\n",
        "                activation=out_activation,).to(DEVICE)\n",
        "    else:\n",
        "        model = smp.Unet(\n",
        "                encoder_name=encoder,\n",
        "                encoder_weights=weights,\n",
        "                in_channels=in_channels,\n",
        "                classes=out_channels,\n",
        "                activation=out_activation,).to(DEVICE)\n",
        "    return model\n",
        "\n",
        "def get_loss(pred, target, func_name):\n",
        "    loss_func = None\n",
        "    if func_name == 'dice':\n",
        "        loss_func = smp.losses.DiceLoss(mode='binary')\n",
        "        loss = loss_func(pred, target)\n",
        "    elif func_name == 'bcelog':\n",
        "        loss_func = nn.BCEWithLogitsLoss()\n",
        "        loss = loss_func(pred, target)\n",
        "    elif func_name == 'jaccard':\n",
        "        loss_func = smp.losses.JaccardLoss(mode='binary')\n",
        "        loss = loss_func(pred, target)\n",
        "    elif func_name == 'weighted_bce':\n",
        "        loss_func = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(4))\n",
        "        loss = loss_func(pred, target)\n",
        "    elif func_name == 'focal':\n",
        "        loss_func = smp.losses.FocalLoss(mode='binary')\n",
        "        loss = loss_func(pred, target)\n",
        "    elif func_name == 'dice+bce':\n",
        "        loss_func1 = smp.losses.DiceLoss(mode='binary')\n",
        "        loss1 = loss_func1(pred, target)\n",
        "        loss_func2 = nn.BCEWithLogitsLoss()\n",
        "        loss2 = loss_func2(pred, target)\n",
        "        loss = loss1 + loss2\n",
        "    elif func_name == 'dice+bce60/40':\n",
        "        loss_func1 = smp.losses.DiceLoss(mode='binary')\n",
        "        loss1 = loss_func1(pred, target)\n",
        "        loss_func2 = nn.BCEWithLogitsLoss()\n",
        "        loss2 = loss_func2(pred, target)\n",
        "        loss = 0.6*loss1 + 0.4*loss2\n",
        "    elif func_name == 'dice+bce40/60':\n",
        "        loss_func1 = smp.losses.DiceLoss(mode='binary')\n",
        "        loss1 = loss_func1(pred, target)\n",
        "        loss_func2 = nn.BCEWithLogitsLoss()\n",
        "        loss2 = loss_func2(pred, target)\n",
        "        loss = 0.4*loss1 + 0.6*loss2\n",
        "    # elif func_name == 'boundary_dou_loss':\n",
        "    #     loss_func = BoundaryDoULoss(n_classes=1)\n",
        "    #     loss = loss_func.forward(pred, target)\n",
        "    elif func_name == 'tversky':\n",
        "        loss_func1 = smp.losses.TverskyLoss(mode='binary', alpha=0.7, beta=0.3)\n",
        "        loss = loss_func(pred, target)\n",
        "    # elif func_name == 'hausdorff':\n",
        "\n",
        "    return loss\n",
        "\n",
        "def wandb_train(config=None):\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        train_loader, val_loader = build_dataloaders(config)\n",
        "        model = build_model(config.model_type, config.dropout, config.loss_function)\n",
        "        optimizer = build_optimizer(model, config)\n",
        "        # loss_fn = get_loss(config.loss_function) #nn.BCEWithLogitsLoss(pos_weight = torch.tensor(4))\n",
        "\n",
        "        for epoch in range(config.epochs):\n",
        "            avg_loss = train_epoch(model, train_loader, optimizer, config.loss_function)#, loss_fn)\n",
        "            # print(avg_loss)\n",
        "            metrics = {\"train/loss\": avg_loss, \"train/epoch\": epoch}\n",
        "            val_loss, dice_score = validate_model(model, val_loader, config.loss_function)\n",
        "            val_metrics = {\"val/val_loss\": val_loss,\n",
        "                           \"val/dice_score\": dice_score}\n",
        "            wandb.log({**metrics, **val_metrics})\n",
        "\n",
        "class DictObject:\n",
        "    def __init__(self, **entries):\n",
        "        self.__dict__.update(entries)\n",
        "\n",
        "def train(config, model_out_path):\n",
        "    if WANDB_LOG:\n",
        "        wandb.init(\n",
        "            project=\"LSEC_segmentation\",\n",
        "            config=config)\n",
        "        config = wandb.config\n",
        "    else:\n",
        "        config = DictObject(**config)\n",
        "\n",
        "    train_loader, val_loader = build_dataloaders(config)\n",
        "    model = build_model(config.model_type, config.dropout, config.loss_function)\n",
        "    optimizer = build_optimizer(model, config)\n",
        "    # loss_fn = build_loss_func(config.loss_function) # nn.BCEWithLogitsLoss(pos_weight = torch.tensor(4))\n",
        "\n",
        "    best_dice_score = 0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    dice_scores = []\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        model.train()\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, config.loss_function)\n",
        "        train_losses.append(train_loss)\n",
        "        val_loss, dice_score = validate_model(model, val_loader, config.loss_function)\n",
        "\n",
        "        if dice_score > best_dice_score: # using dice score right now\n",
        "            save_state_dict(model, model_out_path)\n",
        "        best_dice_score = max(dice_score, best_dice_score)\n",
        "\n",
        "        dice_scores.append(dice_score)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f'Dice score: {dice_score}')\n",
        "        # view_prediction(val_loader, model, device = DEVICE)\n",
        "        if WANDB_LOG:\n",
        "            wandb.log({\"train/train_loss\": train_loss,\n",
        "                       \"train/epoch\": epoch,\n",
        "                       \"val/val_loss\": val_loss,\n",
        "                       \"val/dice_score\":dice_score,\n",
        "                       })\n",
        "    if WANDB_LOG:\n",
        "        wandb.finish()\n",
        "\n",
        "    return train_losses, val_losses, dice_scores"
      ],
      "metadata": {
        "id": "c6sxUMdmjwo6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = \"./gdrive/MyDrive/lsecs/cropped_selections\"\n",
        "data_split = 0.1\n",
        "\n",
        "# wandb sweep config\n",
        "sweep_config = {\n",
        "    'method': 'grid'#'bayes'\n",
        "    }\n",
        "metric = {\n",
        "    'name': 'val/dice_score',\n",
        "    'goal': 'maximize'\n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "parameters_dict = {\n",
        "    'optimizer': {\n",
        "        # 'values': ['adam', 'sgd']\n",
        "        'value': 'sgd'\n",
        "        },\n",
        "    'learning_rate': {\n",
        "        'value': 0.0186,\n",
        "        # # a flat distribution between min and max\n",
        "        # 'distribution': 'uniform',\n",
        "        # 'min': 0.01,\n",
        "        # 'max': 0.02\n",
        "      },\n",
        "    'weight_decay': {\n",
        "        'value': 0.0189,\n",
        "        # 'distribution': 'uniform',\n",
        "        # 'min': 0.01,\n",
        "        # 'max' : 0.02,\n",
        "    },\n",
        "    # sgd parameters\n",
        "    'momentum':{\n",
        "        'value': 0.0722,\n",
        "        # 'distribution': 'uniform',\n",
        "        # 'min': 0.06,\n",
        "        # 'max' : 0.08,\n",
        "    },\n",
        "\n",
        "    'dropout': {\n",
        "        'value': 0.0,\n",
        "        #   'values': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "        },\n",
        "    'epochs': {\n",
        "        'value': 12\n",
        "        },\n",
        "\n",
        "    # Dataloader params\n",
        "    'image_patches_path': {\n",
        "        'value': output_folder\n",
        "        },\n",
        "    'mask_patches_path': {\n",
        "        'value': output_folder\n",
        "        },\n",
        "    'data_split': {\n",
        "        'value': data_split\n",
        "        },\n",
        "    'batch_size': {\n",
        "        'value': 6,\n",
        "        # # integers between min and max\n",
        "        # # with evenly-distributed logarithms\n",
        "        # 'distribution': 'q_log_uniform_values',\n",
        "        # 'q': 2, # the discrete step of the distribution\n",
        "        # 'min': 4,\n",
        "        # 'max': 8,\n",
        "      },\n",
        "    # Adam parameters\n",
        "    # 'beta1': {\n",
        "    #     'distribution': 'uniform',\n",
        "    #     'min': 0.95,\n",
        "    #     'max' : 0.999,\n",
        "    # },\n",
        "    # 'beta2': {\n",
        "    #     'distribution': 'uniform',\n",
        "    #     'min': 0.95,\n",
        "    #     'max' : 0.999,\n",
        "    # },\n",
        "        # 'fc_layer_size': {\n",
        "    #     'values': [128, 256, 512]\n",
        "    #     },\n",
        "    'image_denoising_methods': {\n",
        "        # 'value': 'median5',\n",
        "        'values': ['nlm', 'no_denoise']\n",
        "        # 'values': ['clahe+median5', 'med7', 'median5', 'median5+clahe', 'wave1_5+med3', 'wave2_5', 'wave2_5+med5'],#['wavelet', 'wavelet+median', 'advanced median'] # k waveletu jeste pridat ruzne thresholdy\n",
        "    },\n",
        "    'loss_function':{\n",
        "        # 'value': 'boundary_dou_loss',\n",
        "        'values': ['dice', 'dice+bce', 'boundary_dou_loss'],#['dice', 'bcelog', 'jaccard', 'weighted_bce', 'focal'],#, 'tversky', 'hausdorff']\n",
        "    },\n",
        "    'model_type':{\n",
        "        # 'values': ['plain_unet', 'resnet34+imagenet', 'resnet50+imagenet', 'inceptionv4+imagenet', 'efficientnet-b7+imagenet', 'resnet18+swsl', 'resnet18+imagenet','vgg11+imagenet'], # not great\n",
        "        # 'values': ['vgg11+imagenet', 'vgg13+imagenet', 'vgg16+imagenet', 'vgg19+imagenet',  'resnet18+ssl','resnet34+imagenet','resnet50+ssl', 'resnext50_32x4d+ssl'], # good\n",
        "        # 'values': ['vgg13+imagenet', 'vgg16+imagenet', 'vgg19+imagenet',  'resnet18+ssl'], # the best so far\n",
        "        'value': 'vgg13+imagenet',\n",
        "    },\n",
        "}\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"LSEC_segmentation\")"
      ],
      "metadata": {
        "id": "Y851Q6gvcd8h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "1b9a87f1-901f-400d-cb6a-e85712a5405a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 23\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: rkr0vujs\n",
            "Sweep URL: https://wandb.ai/dpd/LSEC_segmentation/sweeps/rkr0vujs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WANDB_CONNECTED = True\n",
        "wandb.agent(sweep_id, wandb_train, count=10)"
      ],
      "metadata": {
        "id": "EXcfFX2wo9P7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4b3a4336bb104ab6b027c5bebaeba4d4",
            "c1363f1037284fe6b5eb59857d1a3155",
            "6620324156b844958ea1153c96bcdc83",
            "f0dd2e71828646679145444fd21bde02",
            "57a6e5df24624deab63d0a434c9d3edc",
            "fceebdcecc7d4ae28d285df7c2f9343e",
            "2d79bcba298046b3ad98d19479865863",
            "1ff28095653f471c9b6d5e380c29a2f6",
            "0e812beb4dec41efa60fbb329e5bc15e",
            "2b3ab8215e994859b0b195d9fceddecc",
            "31c0575643fe47e78b6d0a883e545e3e",
            "6987205147294d4eb56e8e3f3fe5c2cd",
            "d2776c98d1f24b89897532e1bf810455",
            "a184badabf0f48f3a7d1e945f32a5125",
            "c97f9f74259544b18567b42b2a80571d",
            "8ab13cb9a1804565b733d262a2a679f7",
            "a619b9d65ec64d159cd8469e292da1f2",
            "1057f1ff51fd40fa8c3865af5991ccd4",
            "140e9a0b8344469eb6d39e4a13135bf6",
            "46446197292d404a918532f8c27b00d2",
            "834b16da2869475ea8ac320ced2e545c",
            "52bdbaaebe8a451e8669f046617098d5",
            "39d41bb97a374bc1ba4ec903dd3acf1c",
            "bf78c19967bb451bbf9f59ecb7b98143",
            "7dee6c4e09944f19b3d5f95d1830818a",
            "61dc8635e4c14ee1834da0c0dfa732d5",
            "001e9a7ac6244608885784c2b3c4cb7b",
            "6f07f80e5c0848feb67b79f2a3a34ceb",
            "51d238a53faa4edb99bd6a16758b7d3b",
            "66030336c6464e5483570810839a4ab5",
            "389851eae945476eb2e159c4b3fcea33",
            "70cf6892831949e6961127b5e6b26240",
            "0b3da0620fd740b6ad69d6666b3d2820",
            "a23bb85bce7c47a1b2664d15ed3f1331",
            "27618d7577a24d6a95c49011812d1d82",
            "8b292c42b2674ffc8aa5c19f0519c63e",
            "a7af4ef3eac940df84658ac707473d85",
            "039734f27b114161820846b8a47579bf",
            "9eceb663801f4ccfa1414b6ad49637d7",
            "99ec4ab9f73d4c1ea3d177a3c7e6725e",
            "7d4663fcd838456a92ca91a397fb5349",
            "6bcef0f91933462281b391adf862eea3",
            "c3bf8c425c3d4207ba4ce91f6cb027d0",
            "b2432fc38ad941efba347ba43033f8e6",
            "4bacb50a28a5481c957b072873dcdea3",
            "ba54b2cf08b746599d89aad04eed96b9",
            "db83867f57e3433798c2f312dae24d83",
            "39f3a53fa0d64bf3bd9f307fc19455e4"
          ]
        },
        "outputId": "e016b91e-0e79-4851-dd1a-fe6846fd90e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gznanmjt with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: nlm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: dice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg13+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarketakvasova1\u001b[0m (\u001b[33mdpd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240428_100250-gznanmjt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/gznanmjt' target=\"_blank\">dark-sweep-1</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/gznanmjt' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/gznanmjt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg13-c768596a.pth\" to /root/.cache/torch/hub/checkpoints/vgg13-c768596a.pth\n",
            "100%|██████████| 508M/508M [00:06<00:00, 78.1MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b3a4336bb104ab6b027c5bebaeba4d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>██▇▇▆▆▅▆▄▃▄▃▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>█▇▅▃▂▂▁▁▁▁▁▁</td></tr><tr><td>val/dice_score</td><td>▁▅▇▇█▇██████</td></tr><tr><td>val/val_loss</td><td>█▇▄▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.10547</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.09579</td></tr><tr><td>val/dice_score</td><td>0.9038</td></tr><tr><td>val/val_loss</td><td>0.10815</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dark-sweep-1</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/gznanmjt' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/gznanmjt</a><br/> View project at: <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_100250-gznanmjt/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mexcx51l with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: nlm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: dice+bce\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg13+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240428_101026-mexcx51l</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/mexcx51l' target=\"_blank\">winter-sweep-2</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/mexcx51l' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/mexcx51l</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.012 MB uploaded\\r'), FloatProgress(value=0.10537356785541391, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e812beb4dec41efa60fbb329e5bc15e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▆▄▃▃▃▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val/dice_score</td><td>▁▄▅▆▇▇▇▇▇███</td></tr><tr><td>val/val_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.08724</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.12229</td></tr><tr><td>val/dice_score</td><td>0.91199</td></tr><tr><td>val/val_loss</td><td>0.14633</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">winter-sweep-2</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/mexcx51l' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/mexcx51l</a><br/> View project at: <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_101026-mexcx51l/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dvq2mwnd with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: nlm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: boundary_dou_loss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg13+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240428_101356-dvq2mwnd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/dvq2mwnd' target=\"_blank\">flowing-sweep-3</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/dvq2mwnd' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/dvq2mwnd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.012 MB uploaded\\r'), FloatProgress(value=0.12706603241151335, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a619b9d65ec64d159cd8469e292da1f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▂▅▃▃▃▅▅▅▃▄▆▅▆▆▆▄▆▆▄▆▃▆▄▁▄█▄▁▆▆▆▅▂▃▅▃▂▄▆▆</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>▅▁▂▇▂█▃▅▄▃▆▇</td></tr><tr><td>val/dice_score</td><td>▂▁▄▃▆▅▅▅▆▇█▇</td></tr><tr><td>val/val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.34471</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.26114</td></tr><tr><td>val/dice_score</td><td>0.15355</td></tr><tr><td>val/val_loss</td><td>0.26496</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">flowing-sweep-3</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/dvq2mwnd' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/dvq2mwnd</a><br/> View project at: <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_101356-dvq2mwnd/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rzujrihm with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: no_denoise\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: dice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg13+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240428_101726-rzujrihm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/rzujrihm' target=\"_blank\">elated-sweep-4</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/rzujrihm' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/rzujrihm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dee6c4e09944f19b3d5f95d1830818a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▇▇▇▇▇▇█▇▇▇▇▇▇▇▆▆▆▅▆▆▆▇▇▃▃▃▃▂▂▃▃▂▁▂▁▂▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>███▇▇▇▆▅▃▂▁▁</td></tr><tr><td>val/dice_score</td><td>▁▂▄▅▆▆▇█████</td></tr><tr><td>val/val_loss</td><td>███▇▇▆▅▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.10095</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.15041</td></tr><tr><td>val/dice_score</td><td>0.87482</td></tr><tr><td>val/val_loss</td><td>0.15151</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">elated-sweep-4</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/rzujrihm' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/rzujrihm</a><br/> View project at: <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_101726-rzujrihm/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1vyyqf83 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: no_denoise\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: dice+bce\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg13+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240428_102503-1vyyqf83</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/1vyyqf83' target=\"_blank\">vivid-sweep-5</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/1vyyqf83' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/1vyyqf83</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.012 MB uploaded\\r'), FloatProgress(value=0.10523344891541005, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b3da0620fd740b6ad69d6666b3d2820"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▆▄▄▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val/dice_score</td><td>▁▃▄▅▅▇▇▇█▇██</td></tr><tr><td>val/val_loss</td><td>█▄▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.10387</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.13188</td></tr><tr><td>val/dice_score</td><td>0.90692</td></tr><tr><td>val/val_loss</td><td>0.15448</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vivid-sweep-5</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/1vyyqf83' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/1vyyqf83</a><br/> View project at: <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_102503-1vyyqf83/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zc1sxceo with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_split: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_denoising_methods: no_denoise\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timage_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0186\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_function: boundary_dou_loss\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmask_patches_path: ./gdrive/MyDrive/lsecs/cropped_selections\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: vgg13+imagenet\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.0722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240428_102833-zc1sxceo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/zc1sxceo' target=\"_blank\">rose-sweep-6</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/sweeps/w4zo6fo4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/zc1sxceo' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/zc1sxceo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.012 MB of 0.012 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d4663fcd838456a92ca91a397fb5349"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▄▂▅▄▄▄▂▄▅▄█▅▅▄█▆▅▁▇▆▃▅▅▄▆▅▇▅▅▆▅▆▄▅▆▆▃▄▇▄</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>train/loss</td><td>█▆▇▄▅▄▁█▆▃▅▅</td></tr><tr><td>val/dice_score</td><td>▇█▇▅▇▄▄▄▃▃▁▁</td></tr><tr><td>val/val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.24137</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/loss</td><td>0.25867</td></tr><tr><td>val/dice_score</td><td>0.09141</td></tr><tr><td>val/val_loss</td><td>0.26502</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rose-sweep-6</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/zc1sxceo' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/zc1sxceo</a><br/> View project at: <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_102833-zc1sxceo/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Training**"
      ],
      "metadata": {
        "id": "KPwZ2wIG8htJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOAD_MODEL = False\n",
        "WANDB_CONNECTED = True\n",
        "WANDB_LOG = True\n",
        "image_patches_path = \"./gdrive/MyDrive/lsecs/cropped_selections/\" # + patches_image_denoising_methods/image_patches\n",
        "mask_patches_path = \"./gdrive/MyDrive/lsecs/cropped_selections/\"\n",
        "model_path = os.path.join(\"./gdrive/MyDrive/lsecs\", f\"vgg13_dice+bce_nlm_checkpoint.pth.tar\")\n",
        "\n",
        "config = {\n",
        "    'batch_size' : 6,\n",
        "    'dropout' : 0.0,\n",
        "    'optimizer' : 'sgd',\n",
        "    'num_epochs' : 15,\n",
        "    'learning_rate' : 0.0186,\n",
        "    'weight_decay' : 0.0189,\n",
        "    'momentum' : 0.0722,\n",
        "    'data_split' : 0.1,\n",
        "    'image_patches_path': image_patches_path,\n",
        "    'mask_patches_path': mask_patches_path,\n",
        "    'image_denoising_methods': 'nlm',\n",
        "    'loss_function': 'dice+bce',\n",
        "    'model_type': 'vgg13+imagenet',\n",
        "}\n"
      ],
      "metadata": {
        "id": "-0Al6T1fdX_-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_MODEL:\n",
        "    model = build_model(config['model_type'], config['dropout'], config['loss_function'])\n",
        "    model = UNET(in_channels=1, out_channels=1, device=DEVICE, dropout_probability=config['dropout'], activations = 'ReLU', out_activation=None).to(DEVICE)\n",
        "    load_state_dict(model, model_path)\n",
        "else:\n",
        "    # WANDB_LOG = False\n",
        "    train_losses, val_losses, dice_scores = train(config, model_path)"
      ],
      "metadata": {
        "id": "IaxEOPPRbMjA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1e927bf3ccc14b9087500f1516e906a0",
            "cfc649ea1b284c47b8ddf3f0fe614164",
            "108c42ee24e84ea2ace48e8843bd6ef2",
            "50b6d4d26f394e51a2840c6eee9a4447",
            "63e36ec48b384b8ca0957b3b8fea6389",
            "c963f3e68630486e8cb6f4aad967a4c7",
            "ddcd15acfe5546b9971db8bf61c40896",
            "d699f0e0a31c4d6ca45fa0ad98d32bab",
            "046bcc30d52046af9f18cde4985352e9",
            "625bea92ac974d8b908174b6bdc4907d",
            "317ab5855b8043bb9bb7a92996b80268",
            "3981d7c944c34bceaa06eba67b56fb33",
            "5b32872d72964627a9290796e76fcc75",
            "d2c2bf379fde42a9afa7b603dd1bdab6",
            "73b283eabb24426bad65ffcbe9dee2bb",
            "51f499282bda4506b198e4494b66ffc3"
          ]
        },
        "outputId": "487f3aa0-9022-4fe1-8206-94d19f2e676e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:gn0nvd15) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.012 MB of 0.012 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e927bf3ccc14b9087500f1516e906a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trim-salad-67</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/gn0nvd15' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/gn0nvd15</a><br/> View project at: <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_104813-gn0nvd15/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:gn0nvd15). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240428_104832-49wt6yza</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dpd/LSEC_segmentation/runs/49wt6yza' target=\"_blank\">confused-planet-68</a></strong> to <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/49wt6yza' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/49wt6yza</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg13-c768596a.pth\" to /root/.cache/torch/hub/checkpoints/vgg13-c768596a.pth\n",
            "100%|██████████| 508M/508M [00:03<00:00, 137MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Saving checkpoint\n",
            "Dice score: 0.8139117360115051\n",
            "=> Saving checkpoint\n",
            "Dice score: 0.8335367441177368\n",
            "=> Saving checkpoint\n",
            "Dice score: 0.8631443977355957\n",
            "=> Saving checkpoint\n",
            "Dice score: 0.8847538232803345\n",
            "=> Saving checkpoint\n",
            "Dice score: 0.888969361782074\n",
            "=> Saving checkpoint\n",
            "Dice score: 0.8981255888938904\n",
            "=> Saving checkpoint\n",
            "Dice score: 0.9048063158988953\n",
            "=> Saving checkpoint\n",
            "Dice score: 0.9067544937133789\n",
            "Dice score: 0.9063440561294556\n",
            "=> Saving checkpoint\n",
            "Dice score: 0.9114024043083191\n",
            "Dice score: 0.9051788449287415\n",
            "Dice score: 0.907321572303772\n",
            "=> Saving checkpoint\n",
            "Dice score: 0.9143697619438171\n",
            "Dice score: 0.9141561388969421\n",
            "=> Saving checkpoint\n",
            "Dice score: 0.9160248041152954\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "046bcc30d52046af9f18cde4985352e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▆▅▄▂▂▂▂▂▂▃▁▃▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train/train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/dice_score</td><td>▁▂▄▆▆▇▇▇▇█▇▇███</td></tr><tr><td>val/val_loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.1171</td></tr><tr><td>train/epoch</td><td>14</td></tr><tr><td>train/train_loss</td><td>0.14467</td></tr><tr><td>val/dice_score</td><td>0.91602</td></tr><tr><td>val/val_loss</td><td>0.14391</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">confused-planet-68</strong> at: <a href='https://wandb.ai/dpd/LSEC_segmentation/runs/49wt6yza' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation/runs/49wt6yza</a><br/> View project at: <a href='https://wandb.ai/dpd/LSEC_segmentation' target=\"_blank\">https://wandb.ai/dpd/LSEC_segmentation</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_104832-49wt6yza/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICjg9JWmLAo9"
      },
      "source": [
        "# Training evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7Ay9PlVUxpq0",
        "outputId": "1e124a69-7280-4cf1-dcc7-84ef9a110d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Time')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hLh2DOF_z7En",
        "outputId": "0f971008-564f-406b-d8f5-a561d3afb00b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(dice_scores, label='Dice score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Dice score')\n",
        "plt.title('Validation Dice Score Over Time')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLmWmnwWbCaZ"
      },
      "source": [
        "# Inference debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtZyUqY3bByz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0c88f9-a6f2-4042-9de2-32a81584d3e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg13-c768596a.pth\" to /root/.cache/torch/hub/checkpoints/vgg13-c768596a.pth\n",
            "100%|██████████| 508M/508M [00:27<00:00, 19.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Inference on full images\n",
        "test_image_path = \"./gdrive/MyDrive/lsec_test/old11_CA150_NE_05.tif\"\n",
        "test_mask_path = \"./gdrive/MyDrive/lsec_test/old11_CA150_NE_05_original_mask.tif\"\n",
        "\n",
        "output_folder = \"./gdrive/MyDrive/lsec_test\"\n",
        "# model = UNET(in_channels=1, out_channels=1, device=DEVICE, dropout_probability=config['dropout'], activation=None).to(DEVICE)\n",
        "model = build_model('vgg13+imagenet', 0.0, 'dice+bce')\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "out_mask_path = inference_on_image_with_overlap(model, test_image_path, output_folder)\n",
        "merge_original_mask(test_image_path, test_mask_path, output_folder)\n",
        "merge_masks(out_mask_path, test_mask_path, output_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Inference loop**"
      ],
      "metadata": {
        "id": "ZiGwUlrqBx1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "#@markdown ##**Insert Google Drive paths:**\n",
        "\n",
        "#@markdown All Google Drive paths should start with ./gdrive/MyDrive/ (Check the folder structure in the left sidebar under **Files**).\n",
        "input_images_folder = './gdrive/MyDrive/lsecs/fenestration_seg/zapotoczny_test/images' #@param {type:\"string\"}\n",
        "output_mask_folder = './gdrive/MyDrive/lsecs/fenestration_seg/zapotoczny_test/vgg13_dice+bce_nlm_nlm-pre' #@param {type:\"string\"}\n",
        "\n",
        "input_images_folder = input_images_folder.strip()\n",
        "output_mask_folder = output_mask_folder.strip()\n",
        "\n",
        "if not os.path.exists(output_mask_folder):\n",
        "    os.makedirs(output_mask_folder)\n",
        "if not os.path.exists(input_images_folder):\n",
        "    print(f'{input_images_folder} does not exist)')"
      ],
      "metadata": {
        "id": "9JALgAucLM_7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference on full images\n",
        "# images_path = \"./gdrive/MyDrive/lsecs/fenestration_seg/sem_images\"\n",
        "# # test_mask_path = \"./gdrive/MyDrive/lsec_test/old11_CA150_NE_05_original_mask.tif\"\n",
        "# output_folder = \"./gdrive/MyDrive/lsecs/fenestration_seg/new_masks\"\n",
        "\n",
        "\n",
        "# images_path = \"./gdrive/MyDrive/lsecs/fenestration_seg/patches/sem_images\"\n",
        "masks_path = \"./gdrive/MyDrive/lsecs/fenestration_seg/zapotoczny_test/edited_masks\"\n",
        "# output_folder = \"./gdrive/MyDrive/lsecs/fenestration_seg/patches/new_masks\"\n",
        "# if not os.path.exists(output_folder):\n",
        "#     os.makedirs(output_folder)\n",
        "\n",
        "image_names = [f for f in sorted(os.listdir(input_images_folder)) if os.path.isfile(os.path.join(input_images_folder, f))]\n",
        "mask_names = [f for f in sorted(os.listdir(masks_path)) if os.path.isfile(os.path.join(masks_path, f))]\n",
        "# print(image_names)\n",
        "model = build_model('vgg13+imagenet', 0.0, 'dice+bce')\n",
        "if torch.cuda.is_available():\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "else:\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "# image_names = image_names[28:]\n",
        "# mask_names = mask_names[28:]"
      ],
      "metadata": {
        "id": "5YvVBtOmB2aG",
        "outputId": "4d153d3d-c172-4670-92bd-a713e2aa6bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg13-c768596a.pth\" to /root/.cache/torch/hub/checkpoints/vgg13-c768596a.pth\n",
            "100%|██████████| 508M/508M [00:05<00:00, 96.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_name, mask_name in zip(image_names, mask_names):\n",
        "    # print(image_name)\n",
        "    print(f'{image_name} - {mask_name}')\n",
        "    image_path = os.path.join(input_images_folder, image_name)\n",
        "    mask_path = os.path.join(masks_path, mask_name)\n",
        "    out_mask_path = inference_on_image_with_overlap(model, image_path, output_mask_folder)\n",
        "    # print(out_mask_path)\n",
        "    # print(image_path, mask_path)\n",
        "    merge_original_mask(image_path, mask_path, output_mask_folder)\n",
        "    merge_masks(out_mask_path, mask_path, output_mask_folder)\n",
        "    # break"
      ],
      "metadata": {
        "id": "OyROv0wvZRUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Exclusion of fenestrations based on diameter and roundness**"
      ],
      "metadata": {
        "id": "StzWoL-FyWjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "#@markdown ##**Insert the pixel size, and min and max fenestration diameters in nanometers:**\n",
        "\n",
        "#@markdown All fenestration with a smaller or larger diameter than the chosen range will be removed from the crated masks.\n",
        "#@markdown (Use dot '.' as the decimal separator, not comma ',').\n",
        "\n",
        "#@markdown Roundness is computed as minor axis length/major axis length of a fitted ellipse.\n",
        "pixel_size_nm = 10.62 #@param {type:\"number\"}\n",
        "min_diameter_nm = 105 #@param {type:\"number\"}\n",
        "max_diameter_nm = 500 #@param {type:\"number\"}\n",
        "min_roundness = 0.2 # @param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "mask_path = './gdrive/MyDrive/lsecs/mask_edit_test' #@param {type:\"string\"}\n",
        "#@markdown If this is checked, the old masks will be deleted.\n",
        "rewrite_images = False # @param {type:\"boolean\"}\n",
        "mask_path = mask_path.strip()\n",
        "mask_names = sorted([f for f in os.listdir(mask_path) if os.path.isfile(os.path.join(mask_path, f))])\n",
        "\n",
        "def remove_contour_from_mask(contour, mask):\n",
        "    # Fill the contour with black pixels\n",
        "    cv.drawContours(mask, [contour], -1, 0, thickness=cv.FILLED)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def remove_fenestrations(mask_path, min_d, max_d, min_roundness, pixel_size_nm):\n",
        "    contours = find_fenestration_contours(mask_path)\n",
        "    fenestration_areas = [cv.contourArea(cnt) * (pixel_size_nm**2) for cnt in contours]\n",
        "    contour_centers = find_contour_centers(contours)\n",
        "    ellipses = fit_ellipses(contours, contour_centers)\n",
        "    roundness_of_ellipses = []\n",
        "    equivalent_diameters = []\n",
        "    fenestration_areas_from_ellipses = []\n",
        "    mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
        "    # cv2_imshow(mask)\n",
        "    # show_fitted_ellipses(mask_path, ellipses)\n",
        "\n",
        "    # Remove all contours that do not fit the chosen conditions\n",
        "    # Also remove all contours that were too small to fit an ellipse\n",
        "    for contour, ellipse in zip(contours, ellipses):\n",
        "        if ellipse is not None:\n",
        "            center, axes, angle = ellipse\n",
        "            # center_x, center_y = center\n",
        "            minor_axis_length, major_axis_length = axes\n",
        "            # print(axes)\n",
        "            roundness = minor_axis_length/major_axis_length\n",
        "            if roundness >= min_roundness:\n",
        "                roundness_of_ellipses.append(roundness)\n",
        "            # rotation_angle = angle\n",
        "            diameter = pixel_size_nm * equivalent_circle_diameter(major_axis_length, minor_axis_length)\n",
        "            # print(contour)\n",
        "            # print(diameter)\n",
        "            if diameter < min_d or diameter > max_d or roundness < min_roundness or np.isnan(diameter):\n",
        "                mask = remove_contour_from_mask(contour, mask)\n",
        "            else:\n",
        "                equivalent_diameters.append(diameter)\n",
        "                fenestration_areas_from_ellipses.append((diameter**2)/4*math.pi)\n",
        "        else:\n",
        "            mask = remove_contour_from_mask(contour, mask)\n",
        "    # cv2_imshow(mask)\n",
        "    # show_statistics(fenestration_areas, fenestration_areas_from_ellipses, roundness_of_ellipses, equivalent_diameters, min_roundness, min_diameter_nm, max_diameter_nm)\n",
        "    equivalent_diameters = np.array(equivalent_diameters)\n",
        "    # print(equivalent_diameters)\n",
        "    if len(equivalent_diameters) > 0:\n",
        "        mean = int(np.nanmean(equivalent_diameters) + 0.5) # This is how to round numbers in python...\n",
        "        std = int(np.nanstd(equivalent_diameters) + 0.5)\n",
        "        print(f\"Mean equavalent diameter: {mean} nm, std: {std} nm \")\n",
        "    return mask\n",
        "\n",
        "\n",
        "#TODO: ukazat statistiky pro celou slozku obrazku\n",
        "\n",
        "if not rewrite_images:\n",
        "    new_mask_path = os.path.join(mask_path, 'edited_masks')\n",
        "    os.makedirs(new_mask_path, exist_ok=True)\n",
        "else:\n",
        "    new_mask_path = mask_path\n",
        "# print(new_mask_path)\n",
        "for mask_name in mask_names:\n",
        "    # print(mask_name)\n",
        "    mask_path_full = os.path.join(mask_path, mask_name)\n",
        "    # print(mask_path)\n",
        "    # mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
        "    edited_mask = remove_fenestrations(mask_path_full, min_diameter_nm, max_diameter_nm, min_roundness, pixel_size_nm)\n",
        "    # print(os.path.join(new_mask_path, mask_name))\n",
        "    cv.imwrite(os.path.join(new_mask_path, mask_name), edited_mask)\n",
        "    # cv.imwrite(os.path.join(new_mask_path, mask_name), mask)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Display the number of circles and their fitted ellipses\n",
        "# print(\"Number of fenestrations:\", len(contours))\n",
        "# print(\"Number of fitted ellipses:\", len(ellipses))\n"
      ],
      "metadata": {
        "id": "tRq0VTv6yrgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e1749b-72a0-4a92-c1bd-bd1b2427b25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean equavalent diameter: 171 nm, std: 45 nm \n",
            "Mean equavalent diameter: 193 nm, std: 47 nm \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Inference evaluation (dice score)**"
      ],
      "metadata": {
        "id": "RxiOKWQb6aFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "#@markdown Insert folders with ground truth masks and created masks for comparison:\n",
        "ground_truth_mask_folder = './gdrive/MyDrive/' #@param {type:\"string\"}\n",
        "created_mask_folder = './gdrive/MyDrive/' #@param {type:\"string\"}\n",
        "\n",
        "ground_truth_mask_folder = ground_truth_mask_folder.strip()\n",
        "created_mask_folder = created_mask_folder.strip()\n",
        "\n",
        "if not os.path.exists(created_mask_folder):\n",
        "    print(\"Ground truth folder does not exist\")\n",
        "    exit()\n",
        "if not os.path.exists(ground_truth_mask_folder):\n",
        "    print(\"Folder with created masks does not exist\")\n",
        "    exit()\n",
        "\n",
        "ground_truth_images = sorted([f for f in os.listdir(ground_truth_mask_folder) if os.path.isfile(os.path.join(ground_truth_mask_folder, f))])\n",
        "new_images = sorted([f for f in os.listdir(created_mask_folder) if os.path.isfile(os.path.join(created_mask_folder, f))])\n",
        "\n",
        "if len(ground_truth_images) != len(new_images):\n",
        "    print('The number of ground truths and created masks differs.')\n",
        "    exit()\n",
        "\n",
        "def compute_dice_score(image1, image2):\n",
        "    image1[image1 == 255] = 1\n",
        "    image2[image2 == 255] = 1\n",
        "    intersection_sum = np.logical_and(image1, image2).sum()\n",
        "    dice_score = 2*intersection_sum/(image1.sum() + image2.sum())\n",
        "    return dice_score\n",
        "\n",
        "dice_scores = []\n",
        "for ground_truth_mask_name, new_mask_name in zip(ground_truth_images, new_images):\n",
        "    print(f'Compare: {ground_truth_mask_name} - {new_mask_name}')\n",
        "    ground_truth_mask_path = os.path.join(ground_truth_images, ground_truth_mask_name)\n",
        "    new_mask_path = os.path.join(new_images, new_mask_name)\n",
        "    ground_truth_mask = cv.imread(ground_truth_mask_path, cv.IMREAD_GRAYSCALE)\n",
        "    new_mask = cv.imread(new_mask_path, cv.IMREAD_GRAYSCALE)\n",
        "    current_dice_score = compute_dice_score(ground_truth_mask, new_mask)\n",
        "    print(f'Dice score: {current_dice_score}')\n",
        "    dice_scores.append(current_dice_score)\n",
        "mean_dice = sum(dice_scores)/len(dice_scores)\n",
        "\n",
        "print(f'Mean dice score is {mean_dice}')\n",
        "\n"
      ],
      "metadata": {
        "id": "U1JDFWEQ6hbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyXUfWY3KtHa"
      },
      "source": [
        "# Bioimageio stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0UWu17Y2fM4"
      },
      "outputs": [],
      "source": [
        "# !pip install \"bioimageio.core>=0.5,<0.6\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7SgQQqm3K8q"
      },
      "outputs": [],
      "source": [
        "# @torch.jit.ignore\n",
        "# def call_np(tensor) -> torch.Tensor:\n",
        "#   na = tensor.numpy()\n",
        "#   # Interesting stuff here\n",
        "#   tt = torch.tensor(na)\n",
        "#   return tt\n",
        "\n",
        "# class MyModule(nn.Module):\n",
        "#     @torch.jit.export\n",
        "#     def forward(self, tensor):\n",
        "#         done = call_np(tensor)\n",
        "#         print (done)\n",
        "\n",
        "# scripted_module = torch.jit.script(MyModule())\n",
        "# print(scripted_module.forward.graph)\n",
        "# empty_tensor = torch.empty(3, 4)\n",
        "# scripted_module.forward(empty_tensor)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2FcX34DwhgX"
      },
      "outputs": [],
      "source": [
        "# import torchvision.transforms as transforms\n",
        "# import numpy as np\n",
        "\n",
        "# @torch.jit.ignore\n",
        "# def denoise_image(tensor) -> torch.Tensor:\n",
        "#   na = tensor.numpy()\n",
        "#   # Interesting stuff here\n",
        "#   tt = torch.tensor(na)\n",
        "#   return tt\n",
        "\n",
        "# class FunctionWrapper(nn.Module):\n",
        "#   def __init__(self, model):\n",
        "#     super(FunctionWrapper, self).__init__()\n",
        "#     self.model = model\n",
        "\n",
        "#     @torch.jit.export\n",
        "#     def forward(self, tensor):\n",
        "#         denoised = denoise_image(tensor)\n",
        "#         return self.model(denoised)\n",
        "\n",
        "\n",
        "\n",
        "# device = torch.device('cpu')\n",
        "# model = UNET(in_channels=1, out_channels=1, device='cpu')\n",
        "# model.load_state_dict(torch.load(biomodel_path, map_location=device))\n",
        "# # model.to(device=device)\n",
        "# model = torch.jit.script(model)\n",
        "# # wrapper = FunctionWrapper(model)\n",
        "# wrapper.to(device=device)\n",
        "# # wrapper = PreprocessingWrapper(denoise, model)\n",
        "# # model = torch.jit.script(wrapper)\n",
        "# #\n",
        "# model.eval()\n",
        "# torchscript_weights_path = os.path.join(biomodel_folder, 'torchscript_weights.pt')\n",
        "# torch.jit.save(model, torchscript_weights_path)\n",
        "\n",
        "# preprocessing=[[{\"name\": \"scale_range\",\n",
        "#                  \"kwargs\": {\"axes\": \"xy\",\n",
        "#                           #  \"min_percentile\": min_percentile,\n",
        "#                             # \"max_percentile\": max_percentile,\n",
        "#                             \"mode\": \"per_sample\"\n",
        "#                             }}]]\n",
        "\n",
        "# threshold = 0.5\n",
        "# postprocessing = [[{\"name\": \"binarize\", \"kwargs\": {\"threshold\": threshold}}]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DU4m7qIy7rt"
      },
      "outputs": [],
      "source": [
        "# input = np.random.rand(1, 1, 512, 512).astype(\"float32\")  # an example input\n",
        "# test_inputs = os.path.join(biomodel_folder, \"test-input.npy\")\n",
        "# test_outputs = os.path.join(biomodel_folder, \"test-output.npy\")\n",
        "# np.save(test_inputs, input)\n",
        "# with torch.no_grad():\n",
        "#   output = model(torch.from_numpy(input)).cpu().numpy() # copy to cpu(is on gpu because of jit.script)\n",
        "#   output = output > threshold\n",
        "# np.save(test_outputs, output)\n",
        "\n",
        "# print(input.shape)\n",
        "# print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaqoBNRJiNKg"
      },
      "outputs": [],
      "source": [
        "# # create markdown documentation for your model\n",
        "# # this should describe how the model was trained, (and on which data)\n",
        "# # and also what to take into consideration when running the model, especially how to validate the model\n",
        "# # here, we just create a stub documentation\n",
        "# doc_path = os.path.join(biomodel_folder, \"doc.md\")\n",
        "# with open(doc_path, \"w\") as f:\n",
        "#     f.write(\"# My First Model\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfMXWAziiNGI"
      },
      "outputs": [],
      "source": [
        "# from bioimageio.core.build_spec import build_model\n",
        "# import torch\n",
        "# # now we can use the build_model function to create the zipped package.\n",
        "# # it takes the path to the weights and data we have just created, as well as additional information\n",
        "# # that will be used to add metadata to the rdf.yaml file in the model zip\n",
        "# # we only use a subset of the available options here, please refer to the advanced examples and to the\n",
        "# # function signature of build_model in order to get an overview of the full functionality\n",
        "# build_model(\n",
        "#     # the weight file and the type of the weights\n",
        "#     weight_uri= torchscript_weights_path,\n",
        "#     weight_type=\"torchscript\",\n",
        "#     # the test input and output data as well as the description of the tensors\n",
        "#     # these are passed as list because we support multiple inputs / outputs per model\n",
        "#     test_inputs=[test_inputs],\n",
        "#     test_outputs=[test_outputs],\n",
        "#     input_axes=[\"bcyx\"],\n",
        "#     output_axes=[\"bcyx\"],\n",
        "#     # where to save the model zip, how to call the model and a short description of it\n",
        "#     output_path=os.path.join(biomodel_folder,\"model.zip\"),\n",
        "#     name=\"MyFirstModel\",\n",
        "#     description=\"a fancy new model\",\n",
        "#     # additional metadata about authors, licenses, citation etc.\n",
        "#     authors=[{\"name\": \"Gizmo\"}],\n",
        "#     license=\"CC-BY-4.0\",\n",
        "#     documentation=doc_path,\n",
        "#     tags=[\"nucleus-segmentation\"],  # the tags are used to make models more findable on the website\n",
        "#     cite=[{\"text\": \"Gizmo et al.\", \"doi\": \"10.1002/xyzacab123\"}],\n",
        "#     pytorch_version=torch.__version__,\n",
        "#     preprocessing=preprocessing,\n",
        "#     postprocessing=postprocessing\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2RJJ5WriND4"
      },
      "outputs": [],
      "source": [
        "# # finally, we test that the expected outptus are reproduced when running the model.\n",
        "# # the 'test_model' function runs this test.\n",
        "# # it will output a list of dictionaries. each dict gives the status of a different test that is being run\n",
        "# # if all of them contain \"status\": \"passed\" then all tests were successful\n",
        "# from bioimageio.core.resource_tests import test_model\n",
        "# import bioimageio.core\n",
        "# my_model = bioimageio.core.load_resource_description(os.path.join(biomodel_folder,\"model.zip\"))\n",
        "# test_model(my_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oyXUfWY3KtHa"
      ],
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b3a4336bb104ab6b027c5bebaeba4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1363f1037284fe6b5eb59857d1a3155",
              "IPY_MODEL_6620324156b844958ea1153c96bcdc83"
            ],
            "layout": "IPY_MODEL_f0dd2e71828646679145444fd21bde02"
          }
        },
        "c1363f1037284fe6b5eb59857d1a3155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57a6e5df24624deab63d0a434c9d3edc",
            "placeholder": "​",
            "style": "IPY_MODEL_fceebdcecc7d4ae28d285df7c2f9343e",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "6620324156b844958ea1153c96bcdc83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d79bcba298046b3ad98d19479865863",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ff28095653f471c9b6d5e380c29a2f6",
            "value": 1
          }
        },
        "f0dd2e71828646679145444fd21bde02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a6e5df24624deab63d0a434c9d3edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fceebdcecc7d4ae28d285df7c2f9343e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d79bcba298046b3ad98d19479865863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ff28095653f471c9b6d5e380c29a2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e812beb4dec41efa60fbb329e5bc15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b3ab8215e994859b0b195d9fceddecc",
              "IPY_MODEL_31c0575643fe47e78b6d0a883e545e3e"
            ],
            "layout": "IPY_MODEL_6987205147294d4eb56e8e3f3fe5c2cd"
          }
        },
        "2b3ab8215e994859b0b195d9fceddecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2776c98d1f24b89897532e1bf810455",
            "placeholder": "​",
            "style": "IPY_MODEL_a184badabf0f48f3a7d1e945f32a5125",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "31c0575643fe47e78b6d0a883e545e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c97f9f74259544b18567b42b2a80571d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ab13cb9a1804565b733d262a2a679f7",
            "value": 1
          }
        },
        "6987205147294d4eb56e8e3f3fe5c2cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2776c98d1f24b89897532e1bf810455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a184badabf0f48f3a7d1e945f32a5125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c97f9f74259544b18567b42b2a80571d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab13cb9a1804565b733d262a2a679f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a619b9d65ec64d159cd8469e292da1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1057f1ff51fd40fa8c3865af5991ccd4",
              "IPY_MODEL_140e9a0b8344469eb6d39e4a13135bf6"
            ],
            "layout": "IPY_MODEL_46446197292d404a918532f8c27b00d2"
          }
        },
        "1057f1ff51fd40fa8c3865af5991ccd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_834b16da2869475ea8ac320ced2e545c",
            "placeholder": "​",
            "style": "IPY_MODEL_52bdbaaebe8a451e8669f046617098d5",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "140e9a0b8344469eb6d39e4a13135bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39d41bb97a374bc1ba4ec903dd3acf1c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf78c19967bb451bbf9f59ecb7b98143",
            "value": 1
          }
        },
        "46446197292d404a918532f8c27b00d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "834b16da2869475ea8ac320ced2e545c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52bdbaaebe8a451e8669f046617098d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39d41bb97a374bc1ba4ec903dd3acf1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf78c19967bb451bbf9f59ecb7b98143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dee6c4e09944f19b3d5f95d1830818a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61dc8635e4c14ee1834da0c0dfa732d5",
              "IPY_MODEL_001e9a7ac6244608885784c2b3c4cb7b"
            ],
            "layout": "IPY_MODEL_6f07f80e5c0848feb67b79f2a3a34ceb"
          }
        },
        "61dc8635e4c14ee1834da0c0dfa732d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51d238a53faa4edb99bd6a16758b7d3b",
            "placeholder": "​",
            "style": "IPY_MODEL_66030336c6464e5483570810839a4ab5",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "001e9a7ac6244608885784c2b3c4cb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_389851eae945476eb2e159c4b3fcea33",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70cf6892831949e6961127b5e6b26240",
            "value": 1
          }
        },
        "6f07f80e5c0848feb67b79f2a3a34ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51d238a53faa4edb99bd6a16758b7d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66030336c6464e5483570810839a4ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "389851eae945476eb2e159c4b3fcea33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70cf6892831949e6961127b5e6b26240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b3da0620fd740b6ad69d6666b3d2820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a23bb85bce7c47a1b2664d15ed3f1331",
              "IPY_MODEL_27618d7577a24d6a95c49011812d1d82"
            ],
            "layout": "IPY_MODEL_8b292c42b2674ffc8aa5c19f0519c63e"
          }
        },
        "a23bb85bce7c47a1b2664d15ed3f1331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7af4ef3eac940df84658ac707473d85",
            "placeholder": "​",
            "style": "IPY_MODEL_039734f27b114161820846b8a47579bf",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "27618d7577a24d6a95c49011812d1d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eceb663801f4ccfa1414b6ad49637d7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99ec4ab9f73d4c1ea3d177a3c7e6725e",
            "value": 1
          }
        },
        "8b292c42b2674ffc8aa5c19f0519c63e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7af4ef3eac940df84658ac707473d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "039734f27b114161820846b8a47579bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9eceb663801f4ccfa1414b6ad49637d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99ec4ab9f73d4c1ea3d177a3c7e6725e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d4663fcd838456a92ca91a397fb5349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bcef0f91933462281b391adf862eea3",
              "IPY_MODEL_c3bf8c425c3d4207ba4ce91f6cb027d0"
            ],
            "layout": "IPY_MODEL_b2432fc38ad941efba347ba43033f8e6"
          }
        },
        "6bcef0f91933462281b391adf862eea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bacb50a28a5481c957b072873dcdea3",
            "placeholder": "​",
            "style": "IPY_MODEL_ba54b2cf08b746599d89aad04eed96b9",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "c3bf8c425c3d4207ba4ce91f6cb027d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db83867f57e3433798c2f312dae24d83",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39f3a53fa0d64bf3bd9f307fc19455e4",
            "value": 1
          }
        },
        "b2432fc38ad941efba347ba43033f8e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bacb50a28a5481c957b072873dcdea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba54b2cf08b746599d89aad04eed96b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db83867f57e3433798c2f312dae24d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f3a53fa0d64bf3bd9f307fc19455e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e927bf3ccc14b9087500f1516e906a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfc649ea1b284c47b8ddf3f0fe614164",
              "IPY_MODEL_108c42ee24e84ea2ace48e8843bd6ef2"
            ],
            "layout": "IPY_MODEL_50b6d4d26f394e51a2840c6eee9a4447"
          }
        },
        "cfc649ea1b284c47b8ddf3f0fe614164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63e36ec48b384b8ca0957b3b8fea6389",
            "placeholder": "​",
            "style": "IPY_MODEL_c963f3e68630486e8cb6f4aad967a4c7",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "108c42ee24e84ea2ace48e8843bd6ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddcd15acfe5546b9971db8bf61c40896",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d699f0e0a31c4d6ca45fa0ad98d32bab",
            "value": 1
          }
        },
        "50b6d4d26f394e51a2840c6eee9a4447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e36ec48b384b8ca0957b3b8fea6389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c963f3e68630486e8cb6f4aad967a4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddcd15acfe5546b9971db8bf61c40896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d699f0e0a31c4d6ca45fa0ad98d32bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "046bcc30d52046af9f18cde4985352e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_625bea92ac974d8b908174b6bdc4907d",
              "IPY_MODEL_317ab5855b8043bb9bb7a92996b80268"
            ],
            "layout": "IPY_MODEL_3981d7c944c34bceaa06eba67b56fb33"
          }
        },
        "625bea92ac974d8b908174b6bdc4907d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b32872d72964627a9290796e76fcc75",
            "placeholder": "​",
            "style": "IPY_MODEL_d2c2bf379fde42a9afa7b603dd1bdab6",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "317ab5855b8043bb9bb7a92996b80268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b283eabb24426bad65ffcbe9dee2bb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51f499282bda4506b198e4494b66ffc3",
            "value": 1
          }
        },
        "3981d7c944c34bceaa06eba67b56fb33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b32872d72964627a9290796e76fcc75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2c2bf379fde42a9afa7b603dd1bdab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73b283eabb24426bad65ffcbe9dee2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f499282bda4506b198e4494b66ffc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}